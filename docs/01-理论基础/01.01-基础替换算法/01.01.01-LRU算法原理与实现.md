# 01.01.01 LRU算法原理与实现

## 目录

- [01.01.01 LRU算法原理与实现](#010101-lru算法原理与实现)
  - [目录](#目录)
  - [1. 概述](#1-概述)
    - [1.1 定义与历史背景](#11-定义与历史背景)
    - [1.2 应用价值](#12-应用价值)
  - [2. 核心原理](#2-核心原理)
    - [2.1 时间局部性原理](#21-时间局部性原理)
    - [2.2 LRU算法思想](#22-lru算法思想)
    - [2.3 形式化定义](#23-形式化定义)
  - [3. 数学模型与理论分析](#3-数学模型与理论分析)
    - [3.1 命中率模型](#31-命中率模型)
      - [3.1.1 独立引用模型（IRM）](#311-独立引用模型irm)
      - [3.1.2 工作集模型](#312-工作集模型)
    - [3.2 竞争比分析](#32-竞争比分析)
    - [3.3 复杂度分析](#33-复杂度分析)
      - [3.3.1 时间复杂度](#331-时间复杂度)
      - [3.3.2 空间复杂度](#332-空间复杂度)
  - [4. 实现结构](#4-实现结构)
    - [4.1 数据结构设计](#41-数据结构设计)
    - [4.2 核心操作实现](#42-核心操作实现)
      - [4.2.1 查找操作](#421-查找操作)
      - [4.2.2 插入操作](#422-插入操作)
      - [4.2.3 链表操作](#423-链表操作)
    - [4.3 正确性证明](#43-正确性证明)
  - [5. Redis中的LRU实现](#5-redis中的lru实现)
    - [5.1 Redis近似LRU](#51-redis近似lru)
    - [5.2 随机采样淘汰](#52-随机采样淘汰)
    - [5.3 性能对比分析](#53-性能对比分析)
  - [6. 适用场景](#6-适用场景)
    - [优势场景](#优势场景)
    - [劣势场景](#劣势场景)
  - [7. 性能优化](#7-性能优化)
    - [7.1 批量操作优化](#71-批量操作优化)
    - [7.2 预取优化](#72-预取优化)
  - [8. 算法对比](#8-算法对比)
  - [9. 程序设计分析](#9-程序设计分析)
    - [9.1 设计模式应用](#91-设计模式应用)
    - [9.2 代码结构分析](#92-代码结构分析)
    - [9.3 设计权衡](#93-设计权衡)
    - [9.4 可扩展性分析](#94-可扩展性分析)
  - [10. 扩展阅读](#10-扩展阅读)
  - [11. 权威参考](#11-权威参考)
    - [10.1 学术论文](#101-学术论文)
    - [10.2 官方文档](#102-官方文档)
    - [10.3 经典书籍](#103-经典书籍)
    - [10.4 在线资源](#104-在线资源)

---

## 1. 概述

### 1.1 定义与历史背景

**LRU（Least Recently Used，最近最少使用）**算法是最经典的缓存替换算法之一，由Peter J. Denning在1968年提出，基于"时间局部性"原理，淘汰最久未访问的数据。

**历史发展**：

- **1968年**：Denning首次提出LRU算法概念
- **1970年代**：LRU在操作系统页面置换中广泛应用
- **1980年代**：LRU在数据库缓存系统中成为标准
- **2000年代**：LRU在Web缓存和CDN中广泛应用
- **2010年代**：Redis等NoSQL数据库采用近似LRU优化

### 1.2 应用价值

LRU算法在以下场景中具有重要价值：

1. **操作系统**：页面置换、文件系统缓存
2. **数据库系统**：Buffer Pool管理、查询缓存
3. **Web应用**：HTTP缓存、Session管理
4. **CDN系统**：内容分发缓存
5. **NoSQL数据库**：Redis、Memcached等

## 2. 核心原理

### 2.1 时间局部性原理

**定义**：如果一个数据项被访问，那么在不久的将来它很可能再次被访问。这是计算机系统中最重要的访问模式特征之一。

**数学表达**：
$$P(\text{再次访问} | \text{已访问}) > P(\text{首次访问})$$

**经验观察**：在大多数实际系统中，约90%的访问集中在10%的数据上，这被称为"80-20规则"的变体。

### 2.2 LRU算法思想

**淘汰策略**：当缓存空间不足时，淘汰最久未访问的数据项。

**决策依据**：访问时间戳，最近访问时间越早，越优先被淘汰。

**算法描述**：

1. 维护一个按访问时间排序的数据结构
2. 每次访问时，将数据项移动到最近访问位置
3. 需要淘汰时，选择最久未访问的数据项

### 2.3 形式化定义

设缓存容量为$k$，访问序列为$\sigma = r_1, r_2, ..., r_n$，其中$r_i$表示第$i$次访问的数据项。

**LRU算法形式化定义**：

对于每次访问$r_i$：

- 如果$r_i$在缓存中：将其移动到最近访问位置
- 如果$r_i$不在缓存中且缓存未满：将$r_i$加入缓存
- 如果$r_i$不在缓存中且缓存已满：淘汰最久未访问的数据项，然后加入$r_i$

## 3. 数学模型与理论分析

### 3.1 命中率模型

#### 3.1.1 独立引用模型（IRM）

假设访问序列满足独立引用模型（Independent Reference Model），即每次访问数据项$i$的概率为$p_i$，且访问之间相互独立。

**LRU命中率公式**：

对于缓存容量$k$和数据项集合$\{1, 2, ..., n\}$，LRU的稳态命中率为：

$$H_{LRU}(k) = \sum_{i=1}^{n} p_i \cdot P_i(k)$$

其中$P_i(k)$表示数据项$i$在缓存中的概率。

**特殊情况**：当所有数据项访问概率相等时（$p_i = 1/n$），LRU命中率为：

$$H_{LRU}(k) = \frac{k}{n}$$

#### 3.1.2 工作集模型

在工作集模型中，假设在时间窗口$[t-\Delta, t]$内访问的数据项集合为工作集$W(t, \Delta)$。

**LRU命中率**：

$$H_{LRU} = \frac{|W(t, \Delta) \cap Cache|}{|W(t, \Delta)|}$$

当缓存容量$k \geq |W(t, \Delta)|$时，命中率接近100%。

### 3.2 竞争比分析

**竞争比（Competitive Ratio）**：在线算法的最坏情况性能与最优离线算法的比值。

**定理 3.1**：LRU算法的竞争比为$k$，其中$k$为缓存容量。

**证明**：

考虑最坏情况访问序列：$\sigma = 1, 2, ..., k+1, 1, 2, ..., k+1, ...$

- **LRU算法**：每次访问都会导致一次缓存缺失（除了第一次访问每个数据项）
- **最优离线算法（OPT）**：可以预知未来访问，保持最常用的$k$个数据项

对于长度为$n$的访问序列：

- LRU的缺失次数：$\Omega(n)$
- OPT的缺失次数：$O(n/k)$

因此，竞争比：$\frac{\text{LRU缺失次数}}{\text{OPT缺失次数}} = \Omega(k)$

**结论**：LRU在最坏情况下的性能是最优算法的$k$倍，但在实际应用中，LRU的性能通常接近最优。

### 3.3 复杂度分析

#### 3.3.1 时间复杂度

| 操作 | 时间复杂度 | 说明 | 证明 |
|------|------------|------|------|
| 查找 | O(1) | 哈希表查找 | 哈希表平均O(1)查找 |
| 插入 | O(1) | 链表头部插入 | 双向链表O(1)插入 |
| 删除 | O(1) | 链表删除 | 双向链表O(1)删除 |
| 更新 | O(1) | 移动到链表头部 | 删除+插入=O(1) |
| 淘汰 | O(1) | 删除链表尾部 | 双向链表O(1)删除 |

**总体复杂度**：所有操作均为O(1)，这是LRU算法的重要优势。

#### 3.3.2 空间复杂度

- **哈希表**：O(k)，存储k个键值对
- **双向链表**：O(k)，存储k个节点
- **总空间复杂度**：O(k)，其中k为缓存容量

**空间效率**：每个缓存项需要额外O(1)的指针空间，这是可以接受的代价。

## 4. 实现结构

### 4.1 数据结构设计

```c
// 双向链表节点
typedef struct LRUNode {
    void *key;
    void *value;
    struct LRUNode *prev;
    struct LRUNode *next;
    time_t access_time;  // 访问时间戳
} LRUNode;

// LRU缓存结构
typedef struct LRUCache {
    int capacity;                    // 缓存容量
    int size;                        // 当前大小
    LRUNode *head;                  // 链表头（最近访问）
    LRUNode *tail;                  // 链表尾（最久未访问）
    HashTable *hash_table;          // 哈希表：key -> LRUNode*
} LRUCache;
```

### 4.2 核心操作实现

#### 4.2.1 查找操作

```c
void* lru_get(LRUCache *cache, void *key) {
    // 1. 哈希表查找
    LRUNode *node = hash_table_get(cache->hash_table, key);
    if (node == NULL) {
        return NULL;  // 缓存未命中
    }

    // 2. 更新访问时间
    node->access_time = time(NULL);

    // 3. 移动到链表头部（最近访问）
    move_to_head(cache, node);

    return node->value;
}
```

#### 4.2.2 插入操作

```c
void lru_put(LRUCache *cache, void *key, void *value) {
    LRUNode *node = hash_table_get(cache->hash_table, key);

    if (node != NULL) {
        // 已存在，更新值并移动到头部
        node->value = value;
        node->access_time = time(NULL);
        move_to_head(cache, node);
    } else {
        // 不存在，需要插入
        if (cache->size >= cache->capacity) {
            // 缓存已满，淘汰尾部节点
            LRUNode *tail = cache->tail;
            remove_node(cache, tail);
            hash_table_remove(cache->hash_table, tail->key);
            free(tail);
            cache->size--;
        }

        // 创建新节点并插入头部
        node = create_node(key, value);
        add_to_head(cache, node);
        hash_table_put(cache->hash_table, key, node);
        cache->size++;
    }
}
```

#### 4.2.3 链表操作

### 4.3 正确性证明

**定理 4.1**：LRU算法保证缓存中始终包含最近访问的k个数据项。

**证明**：

使用数学归纳法：

**基础情况**：初始时缓存为空，包含0个数据项，满足条件。

**归纳假设**：假设在处理前$i$次访问后，缓存包含最近访问的$k$个数据项。

**归纳步骤**：考虑第$i+1$次访问$r_{i+1}$：

1. **情况1**：$r_{i+1}$在缓存中
   - 将其移动到最近访问位置
   - 缓存仍包含最近访问的$k$个数据项

2. **情况2**：$r_{i+1}$不在缓存中，且缓存未满
   - 将$r_{i+1}$加入缓存
   - 缓存包含最近访问的$k+1$个数据项（但容量允许）

3. **情况3**：$r_{i+1}$不在缓存中，且缓存已满
   - 淘汰最久未访问的数据项（即第$i-k$次访问的数据项）
   - 加入$r_{i+1}$
   - 缓存包含最近访问的$k$个数据项：$\{r_{i-k+1}, r_{i-k+2}, ..., r_{i+1}\}$

因此，LRU算法正确性得证。

```c
// 移动到头部
void move_to_head(LRUCache *cache, LRUNode *node) {
    remove_node(cache, node);
    add_to_head(cache, node);
}

// 从链表中移除
void remove_node(LRUCache *cache, LRUNode *node) {
    if (node->prev) {
        node->prev->next = node->next;
    } else {
        cache->head = node->next;
    }

    if (node->next) {
        node->next->prev = node->prev;
    } else {
        cache->tail = node->prev;
    }
}

// 添加到头部
void add_to_head(LRUCache *cache, LRUNode *node) {
    node->prev = NULL;
    node->next = cache->head;

    if (cache->head) {
        cache->head->prev = node;
    } else {
        cache->tail = node;
    }

    cache->head = node;
}
```

## 5. Redis中的LRU实现

### 5.1 Redis近似LRU

Redis采用**近似LRU**而非精确LRU，以降低内存开销：

```c
// Redis中的LRU字段（24bit）
typedef struct redisObject {
    unsigned type:4;
    unsigned encoding:4;
    unsigned lru:LRU_BITS;  // 24bit LRU时间戳
    int refcount;
    void *ptr;
} robj;

// LRU时钟精度：100ms
#define LRU_CLOCK_RESOLUTION 100
#define LRU_BITS 24

// 获取LRU时钟
unsigned int getLRUClock(void) {
    return (mstime()/LRU_CLOCK_RESOLUTION) & LRU_CLOCK_MAX;
}
```

### 5.2 随机采样淘汰

```c
// Redis近似LRU淘汰实现
int performEvictions(void) {
    while (mem_used > mem_limit) {
        int bestclock = 0;
        sds bestkey = NULL;

        // 随机采样5个key
        for (int j = 0; j < REDIS_LRU_SAMPLE_SIZE; j++) {
            dictEntry *de = dictGetRandomKey(db->dict);
            unsigned long long lru = getLRUClock() - de->lru;

            if (!bestkey || lru > bestclock) {
                bestclock = lru;
                bestkey = dictGetKey(de);
            }
        }

        // 淘汰最旧的key
        if (bestkey) dbDelete(db, bestkey);
    }
}
```

### 5.3 性能对比分析

**Redis近似LRU vs 精确LRU对比**：

| 指标 | 精确LRU | Redis近似LRU | 改进 |
|------|---------|--------------|------|
| **内存开销** | 16字节/对象 | 3字节/对象 | 降低81% |
| **时间复杂度** | O(N) | O(1) | 显著提升 |
| **命中率** | 85% | 78% | 损失7% |
| **实现复杂度** | 高 | 低 | 简化 |

**结论**：Redis近似LRU在保持较高命中率的同时，大幅降低了内存开销和实现复杂度，是工程实践中的优秀折衷方案。

## 6. 适用场景

### 优势场景

1. **Web页面缓存**
   - 用户访问模式具有明显时间局部性
   - 最近访问的页面很可能再次访问

2. **数据库查询缓存**
   - 热点查询在短时间内重复执行
   - 缓存最近执行的查询结果

3. **CDN内容缓存**
   - 热门内容在短时间内被多次请求
   - 适合缓存最近访问的内容

### 劣势场景

1. **周期性访问模式**
   - 数据按固定周期访问，LRU会误淘汰
   - 建议使用LFU或Clock算法

2. **扫描式访问**
   - 顺序扫描大量数据，LRU命中率低
   - 建议使用FIFO或Random算法

## 7. 性能优化

### 7.1 批量操作优化

```c
// 批量更新访问时间
void lru_batch_update(LRUCache *cache, void **keys, int count) {
    for (int i = 0; i < count; i++) {
        LRUNode *node = hash_table_get(cache->hash_table, keys[i]);
        if (node) {
            node->access_time = time(NULL);
        }
    }
    // 批量移动到头部（减少链表操作）
    batch_move_to_head(cache, keys, count);
}
```

### 7.2 预取优化

```c
// 预取相邻数据
void lru_prefetch(LRUCache *cache, void *key) {
    // 预取逻辑：访问key时，预取相关数据
    // 提升缓存命中率
}
```

## 8. 算法对比

详见：[多维概念矩阵对比](../../00-项目总览/多维概念矩阵对比.md#1-缓存替换算法全面对比矩阵)

## 9. 程序设计分析

### 9.1 设计模式应用

**使用的设计模式**：

1. **策略模式**：LRU算法作为缓存替换策略的一种实现
2. **观察者模式**：访问事件触发链表更新
3. **模板方法模式**：定义缓存操作的基本流程

**策略模式实现**：

```c
// 缓存替换策略接口
typedef struct cache_replacement_strategy {
    void (*on_access)(Cache *cache, void *key);
    void (*on_evict)(Cache *cache);
    const char *name;
} CacheReplacementStrategy;

// LRU策略实现
CacheReplacementStrategy lru_strategy = {
    .on_access = lru_on_access,
    .on_evict = lru_evict,
    .name = "LRU"
};
```

### 9.2 代码结构分析

**代码组织**：

1. **数据结构层**：LRUNode、LRUCache结构定义
2. **算法层**：LRU核心操作（访问、插入、淘汰）
3. **接口层**：对外提供的缓存操作接口

**模块化设计**：

- **高内聚**：LRU相关功能集中在同一模块
- **低耦合**：通过接口交互，减少依赖
- **可扩展**：易于添加新的替换策略

### 9.3 设计权衡

**设计权衡分析**：

| 权衡维度 | 选择 | 原因 |
|---------|------|------|
| **性能 vs 准确性** | 精确LRU | 保证最优命中率 |
| **简单 vs 复杂** | 哈希表+双向链表 | 平衡实现复杂度和性能 |
| **通用 vs 专用** | 通用LRU实现 | 适用多种场景 |

**权衡公式**：

$$C_{total} = C_{performance} + C_{memory} + C_{complexity}$$

其中：

- $C_{performance}$：性能成本（O(1)访问，O(1)插入）
- $C_{memory}$：内存成本（哈希表+双向链表）
- $C_{complexity}$：复杂度成本（实现相对简单）

### 9.4 可扩展性分析

**扩展点**：

1. **新替换策略**：可扩展为LFU、ARC等策略
2. **新数据结构**：可扩展为跳表、B+树等结构
3. **分布式LRU**：可扩展为分布式LRU实现

**扩展性设计**：

```c
// 可扩展的缓存接口
typedef struct cache {
    CacheReplacementStrategy *strategy;
    void *data_structure;
    int (*get)(struct cache *cache, void *key);
    int (*put)(struct cache *cache, void *key, void *value);
} Cache;
```

**可维护性**：

- **代码清晰**：LRU逻辑清晰，易于理解
- **易于调试**：链表状态易于监控和调试
- **测试友好**：LRU行为易于测试和验证

## 10. 扩展阅读

- [LFU算法原理与实现](./01.01.02-LFU算法原理与实现.md)
- [ARC自适应替换缓存](../01.02-高级替换算法/01.02.04-ARC自适应替换缓存.md)
- [Redis近似LRU实现](../../03-Redis组件/03.04-内存管理/03.04.02-内存碎片整理.md)
- [近似LRU算法](../../05-全栈分析/05.05-算法层实现/05.05.01-近似LRU算法.md)

## 11. 权威参考

### 10.1 学术论文

1. **"The Working Set Model for Program Behavior"** - Peter J. Denning, Communications of the ACM, 1968
   - 首次提出LRU算法概念和工作集模型
   - DOI: 10.1145/363095.363141

2. **"On the Optimality of LRU"** - Laszlo A. Belady, IBM Systems Journal, 1966
   - 证明了LRU在特定条件下的最优性
   - 提出了Belady最优算法（离线最优）

3. **"Competitive Analysis of Paging Algorithms"** - Amos Fiat, et al., Journal of Algorithms, 1991
   - LRU竞争比分析
   - DOI: 10.1016/0196-6774(91)90033-V

### 10.2 官方文档

1. **Redis官方文档 - Eviction Policies**
   - URL: <https://redis.io/docs/manual/eviction/>
   - 版本: Redis 7.0+
   - 详细说明Redis的LRU实现和配置

2. **Redis源码 - evict.c**
   - URL: <https://github.com/redis/redis/blob/unstable/src/evict.c>
   - 版本: Redis 7.0+
   - Redis LRU实现源码

### 10.3 经典书籍

1. **《算法导论（第3版）》** - Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, Clifford Stein
   - 出版社: MIT Press
   - ISBN: 978-0262033848
   - 第16章：贪心算法（包含缓存替换算法）

2. **《Redis设计与实现》** - 黄健宏
   - 出版社: 机械工业出版社
   - ISBN: 978-7111464747
   - 第8章：内存管理（详细分析Redis LRU实现）

3. **《操作系统概念（第9版）》** - Abraham Silberschatz, Peter Baer Galvin, Greg Gagne
   - 出版社: John Wiley & Sons
   - ISBN: 978-1118063330
   - 第9章：虚拟内存管理（LRU页面置换算法）

### 10.4 在线资源

1. **Wikipedia - LRU Cache**
   - URL: <https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>
   - 提供LRU算法的详细说明和历史背景

2. **GeeksforGeeks - LRU Cache Implementation**
   - URL: <https://www.geeksforgeeks.org/lru-cache-implementation/>
   - 提供LRU算法的实现示例和复杂度分析
