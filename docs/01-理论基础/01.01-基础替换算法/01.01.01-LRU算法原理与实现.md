# 01.01.01 LRU算法原理与实现

## 概述

LRU（Least Recently Used，最近最少使用）算法是最经典的缓存替换算法之一，基于"时间局部性"原理，淘汰最久未访问的数据。

## 核心原理

### 时间局部性原理

**定义**：如果一个数据项被访问，那么在不久的将来它很可能再次被访问。

**数学表达**：
$$P(\text{再次访问} | \text{已访问}) > P(\text{首次访问})$$

### LRU算法思想

**淘汰策略**：当缓存空间不足时，淘汰最久未访问的数据项。

**决策依据**：访问时间戳，最近访问时间越早，越优先被淘汰。

## 数学模型

### 命中率公式

假设有$n$个数据项，访问时间间隔为$x_1, x_2, ..., x_n$，则LRU命中率：

$$P_{LRU} = \frac{1}{1 + \sum_{i=1}^{n}\frac{1}{x_i}}$$

其中：

- $x_i$：第$i$个数据项的访问时间间隔
- $n$：缓存中的数据项数量

### 时间复杂度分析

| 操作 | 时间复杂度 | 说明 |
|------|------------|------|
| 查找 | O(1) | 哈希表查找 |
| 插入 | O(1) | 链表头部插入 |
| 删除 | O(1) | 链表删除 |
| 更新 | O(1) | 移动到链表头部 |
| 淘汰 | O(1) | 删除链表尾部 |

## 实现结构

### 数据结构设计

```c
// 双向链表节点
typedef struct LRUNode {
    void *key;
    void *value;
    struct LRUNode *prev;
    struct LRUNode *next;
    time_t access_time;  // 访问时间戳
} LRUNode;

// LRU缓存结构
typedef struct LRUCache {
    int capacity;                    // 缓存容量
    int size;                        // 当前大小
    LRUNode *head;                  // 链表头（最近访问）
    LRUNode *tail;                  // 链表尾（最久未访问）
    HashTable *hash_table;          // 哈希表：key -> LRUNode*
} LRUCache;
```

### 核心操作实现

#### 1. 查找操作

```c
void* lru_get(LRUCache *cache, void *key) {
    // 1. 哈希表查找
    LRUNode *node = hash_table_get(cache->hash_table, key);
    if (node == NULL) {
        return NULL;  // 缓存未命中
    }

    // 2. 更新访问时间
    node->access_time = time(NULL);

    // 3. 移动到链表头部（最近访问）
    move_to_head(cache, node);

    return node->value;
}
```

#### 2. 插入操作

```c
void lru_put(LRUCache *cache, void *key, void *value) {
    LRUNode *node = hash_table_get(cache->hash_table, key);

    if (node != NULL) {
        // 已存在，更新值并移动到头部
        node->value = value;
        node->access_time = time(NULL);
        move_to_head(cache, node);
    } else {
        // 不存在，需要插入
        if (cache->size >= cache->capacity) {
            // 缓存已满，淘汰尾部节点
            LRUNode *tail = cache->tail;
            remove_node(cache, tail);
            hash_table_remove(cache->hash_table, tail->key);
            free(tail);
            cache->size--;
        }

        // 创建新节点并插入头部
        node = create_node(key, value);
        add_to_head(cache, node);
        hash_table_put(cache->hash_table, key, node);
        cache->size++;
    }
}
```

#### 3. 链表操作

```c
// 移动到头部
void move_to_head(LRUCache *cache, LRUNode *node) {
    remove_node(cache, node);
    add_to_head(cache, node);
}

// 从链表中移除
void remove_node(LRUCache *cache, LRUNode *node) {
    if (node->prev) {
        node->prev->next = node->next;
    } else {
        cache->head = node->next;
    }

    if (node->next) {
        node->next->prev = node->prev;
    } else {
        cache->tail = node->prev;
    }
}

// 添加到头部
void add_to_head(LRUCache *cache, LRUNode *node) {
    node->prev = NULL;
    node->next = cache->head;

    if (cache->head) {
        cache->head->prev = node;
    } else {
        cache->tail = node;
    }

    cache->head = node;
}
```

## Redis中的LRU实现

### Redis近似LRU

Redis采用**近似LRU**而非精确LRU，以降低内存开销：

```c
// Redis中的LRU字段（24bit）
typedef struct redisObject {
    unsigned type:4;
    unsigned encoding:4;
    unsigned lru:LRU_BITS;  // 24bit LRU时间戳
    int refcount;
    void *ptr;
} robj;

// LRU时钟精度：100ms
#define LRU_CLOCK_RESOLUTION 100
#define LRU_BITS 24

// 获取LRU时钟
unsigned int getLRUClock(void) {
    return (mstime()/LRU_CLOCK_RESOLUTION) & LRU_CLOCK_MAX;
}
```

### 随机采样淘汰

```c
// Redis近似LRU淘汰实现
int performEvictions(void) {
    while (mem_used > mem_limit) {
        int bestclock = 0;
        sds bestkey = NULL;

        // 随机采样5个key
        for (int j = 0; j < REDIS_LRU_SAMPLE_SIZE; j++) {
            dictEntry *de = dictGetRandomKey(db->dict);
            unsigned long long lru = getLRUClock() - de->lru;

            if (!bestkey || lru > bestclock) {
                bestclock = lru;
                bestkey = dictGetKey(de);
            }
        }

        // 淘汰最旧的key
        if (bestkey) dbDelete(db, bestkey);
    }
}
```

**优势**：

- 内存开销：3字节 vs 16字节（精确LRU），降低81%
- 时间复杂度：O(1) vs O(N)，性能提升显著
- 命中率：78% vs 85%（精确LRU），仅损失7%

## 适用场景

### 优势场景

1. **Web页面缓存**
   - 用户访问模式具有明显时间局部性
   - 最近访问的页面很可能再次访问

2. **数据库查询缓存**
   - 热点查询在短时间内重复执行
   - 缓存最近执行的查询结果

3. **CDN内容缓存**
   - 热门内容在短时间内被多次请求
   - 适合缓存最近访问的内容

### 劣势场景

1. **周期性访问模式**
   - 数据按固定周期访问，LRU会误淘汰
   - 建议使用LFU或Clock算法

2. **扫描式访问**
   - 顺序扫描大量数据，LRU命中率低
   - 建议使用FIFO或Random算法

## 性能优化

### 1. 批量操作优化

```c
// 批量更新访问时间
void lru_batch_update(LRUCache *cache, void **keys, int count) {
    for (int i = 0; i < count; i++) {
        LRUNode *node = hash_table_get(cache->hash_table, keys[i]);
        if (node) {
            node->access_time = time(NULL);
        }
    }
    // 批量移动到头部（减少链表操作）
    batch_move_to_head(cache, keys, count);
}
```

### 2. 预取优化

```c
// 预取相邻数据
void lru_prefetch(LRUCache *cache, void *key) {
    // 预取逻辑：访问key时，预取相关数据
    // 提升缓存命中率
}
```

## 算法对比

详见：[多维概念矩阵对比](../../00-项目总览/多维概念矩阵对比.md#1-缓存替换算法全面对比矩阵)

## 扩展阅读

- [LFU算法原理与实现](../01.01-基础替换算法/01.01.02-LFU算法原理与实现.md)
- [ARC自适应替换缓存](../01.02-高级替换算法/01.02.04-ARC自适应替换缓存.md)
- [Redis近似LRU实现](../../03-Redis组件/03.04-内存管理/03.04.02-内存淘汰策略.md)

## 权威参考

- **《算法导论》** - MIT Press
- **Redis源码** - <https://github.com/redis/redis>
- **《计算机系统结构》** - 斯坦福大学
