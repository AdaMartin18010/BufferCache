# 01.03.01 一致性哈希原理

## 概述

一致性哈希（Consistent Hashing）是分布式缓存系统中的核心算法，用于解决节点动态增减时的数据迁移问题，最小化数据重新分布。

## 问题背景

### 传统哈希的问题

```python
# 传统哈希：hash(key) % N
def get_server(key, server_count):
    return hash(key) % server_count

# 问题：当服务器数量变化时，大部分数据需要重新分布
# 例如：3台服务器变为4台，75%的数据需要迁移
```

### 一致性哈希的优势

- **节点增减**：只影响相邻节点的数据
- **负载均衡**：数据分布相对均匀
- **容错性**：节点故障时影响范围小

## 算法原理

### 哈希环

```
        0
        |
    ┌───┴───┐
    │       │
  270       90
    │       │
    └───┬───┘
       180
```

**特点**：
- 将哈希空间组织成环形（0-2^32-1）
- 节点和key都映射到环上
- key顺时针找到的第一个节点就是目标节点

### 基本实现

```python
import hashlib
import bisect

class ConsistentHash:
    def __init__(self, nodes=None, replicas=3):
        self.replicas = replicas  # 虚拟节点数
        self.ring = {}            # 哈希环
        self.sorted_keys = []     # 排序的键列表

        if nodes:
            for node in nodes:
                self.add_node(node)

    def _hash(self, key):
        """计算哈希值"""
        return int(hashlib.md5(key.encode()).hexdigest(), 16)

    def add_node(self, node):
        """添加节点"""
        for i in range(self.replicas):
            virtual_key = f"{node}:{i}"
            hash_value = self._hash(virtual_key)
            self.ring[hash_value] = node
            bisect.insort(self.sorted_keys, hash_value)

    def remove_node(self, node):
        """移除节点"""
        for i in range(self.replicas):
            virtual_key = f"{node}:{i}"
            hash_value = self._hash(virtual_key)
            del self.ring[hash_value]
            self.sorted_keys.remove(hash_value)

    def get_node(self, key):
        """获取key对应的节点"""
        if not self.ring:
            return None

        hash_value = self._hash(key)

        # 二分查找：找到第一个大于等于hash_value的节点
        idx = bisect.bisect_right(self.sorted_keys, hash_value)

        # 如果超出范围，回到环的开头
        if idx == len(self.sorted_keys):
            idx = 0

        return self.ring[self.sorted_keys[idx]]
```

## 虚拟节点

### 问题：负载不均衡

```
实际节点分布：
Node A: 0-90度
Node B: 90-180度
Node C: 180-270度
Node D: 270-360度

问题：如果数据分布不均匀，某些节点负载过高
```

### 解决方案：虚拟节点

```python
# 每个物理节点映射到多个虚拟节点
# 虚拟节点数越多，负载越均衡

class ConsistentHashWithVirtualNodes:
    def __init__(self, nodes=None, replicas=150):
        self.replicas = replicas  # 虚拟节点数（推荐150）
        self.ring = {}
        self.sorted_keys = []

        if nodes:
            for node in nodes:
                self.add_node(node)

    def add_node(self, node):
        """添加节点（创建虚拟节点）"""
        for i in range(self.replicas):
            virtual_key = f"{node}:vnode:{i}"
            hash_value = self._hash(virtual_key)
            self.ring[hash_value] = node
            bisect.insort(self.sorted_keys, hash_value)
```

**效果**：
- 虚拟节点数=3：负载方差较大
- 虚拟节点数=150：负载方差<5%
- **推荐值**：150个虚拟节点

## 数据迁移

### 节点添加

```python
# 添加节点时，只影响相邻节点的数据
def add_node_analysis():
    # 假设有3个节点，添加第4个节点
    # 传统哈希：75%的数据需要迁移
    # 一致性哈希：约25%的数据需要迁移（只影响相邻节点）

    # 迁移量 = 1 / (N + 1)
    # N = 当前节点数
    migration_ratio = 1 / (3 + 1)  # 25%
```

### 节点移除

```python
# 移除节点时，数据迁移到下一个节点
def remove_node_analysis():
    # 假设有4个节点，移除1个节点
    # 传统哈希：100%的数据需要重新计算
    # 一致性哈希：约25%的数据需要迁移

    migration_ratio = 1 / 4  # 25%
```

## Redis Cluster中的应用

### 槽位分配

```c
// Redis Cluster使用16384个槽位
#define CLUSTER_SLOTS 16384

// 槽位分配算法
unsigned int keyHashSlot(char *key, int keylen) {
    int s, e;

    // 查找{...}标签
    for (s = 0; s < keylen; s++)
        if (key[s] == '{') break;

    if (s == keylen) return crc16(key, keylen) & 0x3FFF;

    for (e = s+1; e < keylen; e++)
        if (key[e] == '}') break;

    if (e == keylen || e == s+1) return crc16(key, keylen) & 0x3FFF;

    // 使用标签计算槽位
    return crc16(key+s+1, e-s-1) & 0x3FFF;
}
```

### 槽位迁移

```c
// 槽位迁移：只迁移特定槽位的数据
void clusterMigrateSlot(int slot, char *target_ip, int target_port) {
    // 1. 标记槽位为迁移中
    clusterSetSlotMigrating(slot, target_ip, target_port);

    // 2. 迁移槽位中的数据
    dictIterator *di = dictGetIterator(server.db[0].dict);
    dictEntry *de;

    while ((de = dictNext(di)) != NULL) {
        robj *key = dictGetKey(de);
        int key_slot = keyHashSlot(key->ptr, sdslen(key->ptr));

        if (key_slot == slot) {
            // 迁移这个key
            migrateKey(key, target_ip, target_port);
        }
    }

    dictReleaseIterator(di);

    // 3. 更新槽位映射
    clusterSetSlotNode(slot, target_node);
}
```

## 性能分析

### 时间复杂度

- **添加节点**：O(log N)，N为虚拟节点数
- **查找节点**：O(log N)，使用二分查找
- **数据迁移**：O(M)，M为需要迁移的数据量

### 负载均衡

```python
# 负载均衡测试
def test_load_balance():
    nodes = ['node1', 'node2', 'node3']
    ch = ConsistentHash(nodes, replicas=150)

    # 模拟10000个key
    key_distribution = {}
    for i in range(10000):
        key = f"key:{i}"
        node = ch.get_node(key)
        key_distribution[node] = key_distribution.get(node, 0) + 1

    # 计算负载方差
    values = list(key_distribution.values())
    mean = sum(values) / len(values)
    variance = sum((x - mean) ** 2 for x in values) / len(values)

    print(f"负载方差: {variance}")
    # 虚拟节点数=150时，方差<100（负载均衡）
```

## 变种算法

### 1. 带权重的哈希

```python
class WeightedConsistentHash:
    def __init__(self, nodes_with_weights):
        self.ring = {}
        self.sorted_keys = []

        for node, weight in nodes_with_weights.items():
            # 权重越高，虚拟节点数越多
            replicas = int(weight * 150)
            for i in range(replicas):
                virtual_key = f"{node}:{i}"
                hash_value = self._hash(virtual_key)
                self.ring[hash_value] = node
                bisect.insort(self.sorted_keys, hash_value)
```

### 2. 跳跃一致性哈希

```python
# Google的跳跃一致性哈希算法
# 时间复杂度：O(log N)，空间复杂度：O(1)
def jump_hash(key, num_buckets):
    import random
    random.seed(key)
    j = 0
    while j < num_buckets:
        key = random.random()
        j = int((j + 1) / key)
    return j - 1
```

## 扩展阅读

- [虚拟节点优化](../01.03-分布式缓存算法/01.03.02-虚拟节点优化.md)
- [Rendezvous哈希](../01.03-分布式缓存算法/01.03.03-Rendezvous哈希.md)
- [Cluster集群模式](../../03-Redis组件/03.03-高可用架构/03.03.03-Cluster集群模式.md)

## 权威参考

- **《分布式系统概念与设计》** - 分布式系统经典教材
- **Consistent Hashing论文** - "Consistent Hashing and Random Trees"
- **Redis Cluster文档** - <https://redis.io/docs/manual/scaling/>
