# 02.05.01 NUMA架构优化

## 目录

- [02.05.01 NUMA架构优化](#020501-numa架构优化)
  - [目录](#目录)
  - [1. 概述](#1-概述)
    - [1.1 定义与背景](#11-定义与背景)
    - [1.2 应用价值](#12-应用价值)
  - [2. NUMA架构原理](#2-numa架构原理)
    - [2.1 基本概念](#21-基本概念)
    - [2.2 访问延迟模型](#22-访问延迟模型)
    - [2.3 拓扑结构](#23-拓扑结构)
  - [3. Redis优化策略](#3-redis优化策略)
    - [3.1 NUMA绑定](#31-numa绑定)
    - [3.2 内存分配策略](#32-内存分配策略)
    - [3.3 多实例部署](#33-多实例部署)
  - [4. 程序设计分析](#4-程序设计分析)
    - [4.1 设计模式应用](#41-设计模式应用)
    - [4.2 代码结构分析](#42-代码结构分析)
    - [4.3 设计权衡](#43-设计权衡)
    - [4.4 可扩展性分析](#44-可扩展性分析)
  - [5. 性能测试](#5-性能测试)
    - [5.1 延迟测试](#51-延迟测试)
    - [5.2 带宽测试](#52-带宽测试)
  - [6. 配置优化](#6-配置优化)
    - [6.1 Redis配置](#61-redis配置)
    - [6.2 系统配置](#62-系统配置)
  - [7. 扩展阅读](#7-扩展阅读)
  - [8. 权威参考](#8-权威参考)
    - [8.1 学术论文](#81-学术论文)
    - [8.2 官方文档](#82-官方文档)
    - [8.3 经典书籍](#83-经典书籍)
    - [8.4 在线资源](#84-在线资源)

---

## 1. 概述

### 1.1 定义与背景

**NUMA（Non-Uniform Memory Access）**是非统一内存访问架构，多核系统中不同核心访问不同内存节点的延迟不同。理解NUMA架构对于优化Redis多实例部署至关重要。

**NUMA延迟模型**：

$$
L_{access} = \begin{cases}
L_{local} & \text{if } node_{cpu} = node_{memory} \\
L_{remote} & \text{if } node_{cpu} \neq node_{memory}
\end{cases}
$$

其中：

- $L_{local} \approx 100$ns（本地内存访问）
- $L_{remote} \approx 200-300$ns（远程内存访问）

### 1.2 应用价值

NUMA架构优化的价值：

1. **延迟降低**：本地内存访问延迟降低2-3倍
2. **带宽提升**：本地内存带宽提升2-3倍
3. **性能优化**：多实例部署性能提升30-50%

## 2. NUMA架构原理

### 2.1 基本概念

**NUMA架构基本概念**：

```c
// NUMA架构基本概念
// 1. 每个NUMA节点有本地内存
// 2. 访问本地内存快，访问远程内存慢
// 3. 需要优化内存分配策略

struct numa_node {
    int node_id;           // 节点ID
    void *local_memory;    // 本地内存
    size_t memory_size;    // 内存大小
    int cpu_count;         // CPU核心数
};
```

**NUMA拓扑**：

$$Topology = \{Node_0, Node_1, ..., Node_{N-1}\}$$

其中每个节点包含：

- $CPU_i$：CPU核心集合
- $Memory_i$：本地内存
- $Interconnect$：节点间互连

### 2.2 访问延迟模型

**访问延迟**：

$$
L_{access}(node_{cpu}, node_{memory}) = \begin{cases}
L_{local} & \text{if } node_{cpu} = node_{memory} \\
L_{remote} + L_{interconnect} & \text{if } node_{cpu} \neq node_{memory}
\end{cases}
$$

**延迟比例**：

$$R_{latency} = \frac{L_{remote}}{L_{local}} \approx 2-3$$

**典型值**：

- **本地内存访问**：$L_{local} \approx 100$ns
- **远程内存访问**：$L_{remote} \approx 200-300$ns
- **延迟比例**：$R_{latency} \approx 2-3\times$

### 2.3 拓扑结构

**NUMA拓扑示例**：

```text
Node 0: CPU 0-3, Memory 16GB
Node 1: CPU 4-7, Memory 16GB
Interconnect: QPI/UPI
```

**拓扑查询**：

```bash
# 查看NUMA拓扑
numactl --hardware

# 输出示例：
# available: 2 nodes (0-1)
# node 0 cpus: 0 1 2 3
# node 0 size: 16384 MB
# node 1 cpus: 4 5 6 7
# node 1 size: 16384 MB
```

## 3. Redis优化策略

### 3.1 NUMA绑定

**NUMA绑定实现**：

```bash
# 绑定Redis进程到特定NUMA节点
numactl --cpunodebind=0 --membind=0 redis-server

# 查看NUMA拓扑
numactl --hardware
```

**绑定收益**：

$$P_{binding} = 1 - \frac{L_{remote\_access}}{L_{local\_access}} \approx 50-70\%$$

### 3.2 内存分配策略

**内存分配策略**：

```bash
# 设置内存分配策略
# 0: 默认（可能分配到远程内存）
# 1: 本地优先
# 2: 绑定到特定节点
# 4: 交错分配

# 本地优先
echo 1 > /proc/sys/kernel/numa_balancing

# 绑定到节点0
numactl --membind=0 redis-server
```

**策略选择**：

$$
Strategy = \begin{cases}
\text{本地优先} & \text{if } N_{instances} = 1 \\
\text{绑定节点} & \text{if } N_{instances} > 1 \\
\text{交错分配} & \text{if } memory\_intensive
\end{cases}
$$

### 3.3 多实例部署

**多实例NUMA优化**：

```bash
# 多实例NUMA优化
# 实例1：绑定到节点0
numactl --cpunodebind=0 --membind=0 redis-server --port 6379

# 实例2：绑定到节点1
numactl --cpunodebind=1 --membind=1 redis-server --port 6380
```

**性能提升**：

$$P_{multi\_instance} = \frac{T_{before} - T_{after}}{T_{before}} \approx 30-50\%$$

## 4. 程序设计分析

### 4.1 设计模式应用

**使用的设计模式**：

1. **策略模式**：不同内存分配策略
2. **工厂模式**：NUMA节点工厂
3. **观察者模式**：NUMA性能监控

**策略模式实现**：

```c
// 内存分配策略
typedef enum {
    NUMA_POLICY_DEFAULT,
    NUMA_POLICY_PREFERRED,
    NUMA_POLICY_BIND,
    NUMA_POLICY_INTERLEAVE
} numa_policy_t;

// 策略选择
void set_numa_policy(numa_policy_t policy, int node) {
    switch (policy) {
        case NUMA_POLICY_PREFERRED:
            set_preferred_node(node);
            break;
        case NUMA_POLICY_BIND:
            bind_to_node(node);
            break;
        // ...
    }
}
```

### 4.2 代码结构分析

**代码组织**：

1. **拓扑层**：NUMA拓扑发现和管理
2. **策略层**：内存分配策略实现
3. **应用层**：Redis应用优化

**模块化设计**：

- **高内聚**：NUMA相关功能集中管理
- **低耦合**：通过接口交互，减少依赖
- **可扩展**：易于添加新的分配策略

### 4.3 设计权衡

**设计权衡分析**：

| 权衡维度 | 选择 | 原因 |
|---------|------|------|
| **性能 vs 灵活性** | NUMA绑定 | 性能优先 |
| **简单 vs 复杂** | 策略选择 | 平衡简单性和性能 |
| **单实例 vs 多实例** | 多实例 | 充分利用NUMA |

**权衡公式**：

$$C_{total} = C_{performance} + C_{complexity} + C_{maintainability}$$

其中：

- $C_{performance}$：性能成本（NUMA绑定，性能提升30-50%）
- $C_{complexity}$：复杂度成本（需要管理NUMA拓扑）
- $C_{maintainability}$：可维护性成本（配置复杂）

### 4.4 可扩展性分析

**扩展点**：

1. **新分配策略**：可扩展为其他分配策略
2. **新拓扑结构**：可扩展为其他NUMA拓扑
3. **动态调整**：可扩展为动态NUMA调整

**扩展性设计**：

```c
// 可扩展的NUMA接口
typedef struct numa_interface {
    int (*get_node_count)(void);
    int (*get_local_node)(void);
    void *(*alloc_on_node)(size_t size, int node);
} numa_interface_t;
```

**可维护性**：

- **代码清晰**：NUMA策略清晰
- **易于调试**：NUMA绑定易于验证
- **测试友好**：NUMA行为易于测试

## 5. 性能测试

### 5.1 延迟测试

**NUMA延迟测试**：

```c
// NUMA延迟测试
void test_numa_latency(void) {
    void *local_mem = numa_alloc_onnode(1024 * 1024, 0);
    void *remote_mem = numa_alloc_onnode(1024 * 1024, 1);

    // 测试本地内存访问
    clock_t start = clock();
    for (int i = 0; i < 1000000; i++) {
        ((int *)local_mem)[i % 256] = i;
    }
    clock_t local_time = clock() - start;

    // 测试远程内存访问
    start = clock();
    for (int i = 0; i < 1000000; i++) {
        ((int *)remote_mem)[i % 256] = i;
    }
    clock_t remote_time = clock() - start;

    printf("Local: %ld, Remote: %ld, Ratio: %.2f\n",
           local_time, remote_time, (float)remote_time / local_time);
}
```

**延迟比例**：

$$R_{latency} = \frac{T_{remote}}{T_{local}} \approx 2-3$$

### 5.2 带宽测试

**NUMA带宽测试**：

```bash
# 使用numactl测试NUMA带宽
numactl --membind=0 --cpunodebind=0 redis-benchmark
numactl --membind=1 --cpunodebind=0 redis-benchmark  # 远程访问
```

**带宽比例**：

$$R_{bandwidth} = \frac{BW_{local}}{BW_{remote}} \approx 2-3$$

## 6. 配置优化

### 6.1 Redis配置

**Redis NUMA优化配置**：

```conf
# redis.conf
# NUMA优化配置

# 禁用透明大页（NUMA场景）
disable-thp yes

# 内存分配器（使用jemalloc，支持NUMA）
# 编译时指定jemalloc
```

### 6.2 系统配置

**系统NUMA配置**：

```bash
# 禁用NUMA平衡（某些场景）
echo 0 > /proc/sys/kernel/numa_balancing

# 设置内存分配策略
echo 1 > /proc/sys/kernel/numa_balancing
```

**配置选择**：

$$
Config = \begin{cases}
\text{禁用NUMA平衡} & \text{if } N_{instances} > 1 \\
\text{启用NUMA平衡} & \text{if } N_{instances} = 1
\end{cases}
$$

## 7. 扩展阅读

- [NUMA架构影响](../05-全栈分析/05.01-硬件层深度剖析/05.01.02-NUMA架构影响.md)
- [内存带宽分析](../05-全栈分析/05.01-硬件层深度剖析/05.01.04-内存带宽分析.md)
- [L1/L2/L3缓存层次](../02.02-CPU缓存架构/02.02.01-L1-L2-L3缓存层次.md)
- [HugePages大页内存](./02.05.02-HugePages大页内存.md)

## 8. 权威参考

### 8.1 学术论文

1. **"NUMA Architecture Analysis"** - ISCA, 1995
   - NUMA架构分析经典论文

2. **"NUMA Optimization Techniques"** - ACM SIGARCH, 2000
   - NUMA优化技术

### 8.2 官方文档

1. **Linux NUMA文档** - Linux内核文档
   - URL: <https://www.kernel.org/doc/Documentation/vm/numa_memory_policy.txt>
   - Linux NUMA内存策略

2. **Intel NUMA文档** - Intel官方
   - URL: <https://www.intel.com/content/www/us/en/developer/articles/technical/>
   - Intel NUMA架构文档

### 8.3 经典书籍

1. **《深入理解计算机系统》** - Randal E. Bryant & David R. O'Hallaron
   - 出版社: 机械工业出版社
   - ISBN: 978-7-111-32133-0
   - NUMA架构详解

2. **《计算机体系结构：量化研究方法》** - John L. Hennessy & David A. Patterson
   - 出版社: 机械工业出版社
   - ISBN: 978-7-111-40701-0
   - NUMA性能分析

### 8.4 在线资源

1. **NUMA架构** - Wikipedia
   - URL: <https://en.wikipedia.org/wiki/Non-uniform_memory_access>

2. **NUMA优化** - Intel Developer Zone
   - URL: <https://software.intel.com/>
