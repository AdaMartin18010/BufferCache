# 02.06.03 程序设计示例

## 目录

- [02.06.03 程序设计示例](#020603-程序设计示例)
  - [目录](#目录)
  - [1. 概述](#1-概述)
    - [1.1 定义与背景](#11-定义与背景)
    - [1.2 设计原则](#12-设计原则)
  - [2. 设计模式](#2-设计模式)
    - [2.1 策略模式](#21-策略模式)
    - [2.2 工厂模式](#22-工厂模式)
    - [2.3 装饰器模式](#23-装饰器模式)
    - [2.4 观察者模式](#24-观察者模式)
  - [3. 代码示例](#3-代码示例)
    - [3.1 缓存客户端](#31-缓存客户端)
      - [3.1.1 Python实现](#311-python实现)
      - [3.1.2 Golang实现](#312-golang实现)
      - [3.1.3 Rust实现](#313-rust实现)
      - [3.1.4 C++实现](#314-c实现)
    - [3.2 连接池](#32-连接池)
      - [3.2.1 Python实现](#321-python实现)
      - [3.2.2 Golang实现](#322-golang实现)
      - [3.2.3 Rust实现](#323-rust实现)
    - [3.3 监控工具](#33-监控工具)
      - [3.3.1 Python实现](#331-python实现)
      - [3.3.2 Golang实现](#332-golang实现)
  - [4. 最佳实践](#4-最佳实践)
    - [4.1 代码组织](#41-代码组织)
    - [4.2 错误处理](#42-错误处理)
    - [4.3 性能优化](#43-性能优化)
  - [5. 测试策略](#5-测试策略)
    - [5.1 单元测试](#51-单元测试)
    - [5.2 集成测试](#52-集成测试)
    - [5.3 压力测试](#53-压力测试)
  - [6. 扩展阅读](#6-扩展阅读)
  - [7. 权威参考](#7-权威参考)
    - [7.1 学术论文](#71-学术论文)
    - [7.2 官方文档](#72-官方文档)
    - [7.3 经典书籍](#73-经典书籍)

---

## 1. 概述

### 1.1 定义与背景

**程序设计示例**提供了缓存系统程序设计的完整示例，包括设计模式应用、代码组织、错误处理和性能优化等最佳实践。

**程序设计的目标**：

1. **可维护性**：代码结构清晰，易于维护
2. **可扩展性**：易于扩展新功能
3. **可靠性**：错误处理完善，系统稳定
4. **性能**：性能优化，满足性能要求

### 1.2 设计原则

**设计原则**：

1. **单一职责原则**：每个类只有一个职责
2. **开闭原则**：对扩展开放，对修改关闭
3. **依赖倒置原则**：依赖抽象而非具体实现
4. **接口隔离原则**：使用多个专门的接口
5. **里氏替换原则**：子类可以替换父类

---

## 2. 设计模式

### 2.1 策略模式

**策略模式**：定义一系列算法，把它们封装起来，并且使它们可以相互替换。

**应用场景**：缓存替换算法（LRU、LFU、ARC等）

**代码示例**：

```python
from abc import ABC, abstractmethod
from typing import Optional, Any

class EvictionStrategy(ABC):
    """缓存淘汰策略接口"""

    @abstractmethod
    def evict(self, cache: dict) -> Optional[str]:
        """淘汰一个key"""
        pass

class LRUStrategy(EvictionStrategy):
    """LRU淘汰策略"""

    def __init__(self):
        self.access_order = []  # 访问顺序列表

    def evict(self, cache: dict) -> Optional[str]:
        """淘汰最久未访问的key"""
        if not cache:
            return None

        # 找到最久未访问的key
        oldest_key = self.access_order[0] if self.access_order else None
        if oldest_key:
            self.access_order.remove(oldest_key)
        return oldest_key

    def access(self, key: str):
        """记录访问"""
        if key in self.access_order:
            self.access_order.remove(key)
        self.access_order.append(key)

class LFUStrategy(EvictionStrategy):
    """LFU淘汰策略"""

    def __init__(self):
        self.frequency = {}  # 访问频率统计

    def evict(self, cache: dict) -> Optional[str]:
        """淘汰访问频率最低的key"""
        if not cache:
            return None

        # 找到访问频率最低的key
        min_freq = min(self.frequency.values()) if self.frequency else 0
        for key, freq in self.frequency.items():
            if freq == min_freq:
                del self.frequency[key]
                return key
        return None

    def access(self, key: str):
        """记录访问"""
        self.frequency[key] = self.frequency.get(key, 0) + 1

class Cache:
    """缓存类（使用策略模式）"""

    def __init__(self, capacity: int, strategy: EvictionStrategy):
        """
        初始化缓存

        Args:
            capacity: 缓存容量
            strategy: 淘汰策略
        """
        self.capacity = capacity
        self.strategy = strategy
        self.cache = {}

    def get(self, key: str) -> Optional[Any]:
        """获取值"""
        if key in self.cache:
            self.strategy.access(key)
            return self.cache[key]
        return None

    def put(self, key: str, value: Any):
        """设置值"""
        if key in self.cache:
            self.cache[key] = value
            self.strategy.access(key)
        else:
            if len(self.cache) >= self.capacity:
                # 淘汰一个key
                evicted_key = self.strategy.evict(self.cache)
                if evicted_key:
                    del self.cache[evicted_key]

            self.cache[key] = value
            self.strategy.access(key)

# 使用示例
# 使用LRU策略
lru_cache = Cache(capacity=3, strategy=LRUStrategy())
lru_cache.put("a", 1)
lru_cache.put("b", 2)
lru_cache.put("c", 3)
lru_cache.get("a")  # 访问a，更新访问顺序
lru_cache.put("d", 4)  # 淘汰b（最久未访问）

# 使用LFU策略
lfu_cache = Cache(capacity=3, strategy=LFUStrategy())
lfu_cache.put("a", 1)
lfu_cache.put("b", 2)
lfu_cache.put("c", 3)
lfu_cache.get("a")  # 访问a，增加频率
lfu_cache.get("a")  # 再次访问a
lfu_cache.put("d", 4)  # 淘汰b（频率最低）
```

---

### 2.2 工厂模式

**工厂模式**：定义一个创建对象的接口，让子类决定实例化哪一个类。

**应用场景**：创建不同类型的缓存客户端

**代码示例**：

```python
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional

class CacheClient(ABC):
    """缓存客户端接口"""

    @abstractmethod
    def get(self, key: str) -> Optional[Any]:
        """获取值"""
        pass

    @abstractmethod
    def set(self, key: str, value: Any, ttl: int = None):
        """设置值"""
        pass

    @abstractmethod
    def delete(self, key: str) -> bool:
        """删除值"""
        pass

class RedisClient(CacheClient):
    """Redis客户端"""

    def __init__(self, host: str, port: int):
        self.host = host
        self.port = port
        # 初始化Redis连接
        print(f"Connecting to Redis at {host}:{port}")

    def get(self, key: str) -> Optional[Any]:
        """获取值"""
        print(f"Redis GET: {key}")
        return f"value_{key}"

    def set(self, key: str, value: Any, ttl: int = None):
        """设置值"""
        print(f"Redis SET: {key} = {value}, TTL = {ttl}")

    def delete(self, key: str) -> bool:
        """删除值"""
        print(f"Redis DELETE: {key}")
        return True

class MemcachedClient(CacheClient):
    """Memcached客户端"""

    def __init__(self, host: str, port: int):
        self.host = host
        self.port = port
        # 初始化Memcached连接
        print(f"Connecting to Memcached at {host}:{port}")

    def get(self, key: str) -> Optional[Any]:
        """获取值"""
        print(f"Memcached GET: {key}")
        return f"value_{key}"

    def set(self, key: str, value: Any, ttl: int = None):
        """设置值"""
        print(f"Memcached SET: {key} = {value}, TTL = {ttl}")

    def delete(self, key: str) -> bool:
        """删除值"""
        print(f"Memcached DELETE: {key}")
        return True

class CacheClientFactory:
    """缓存客户端工厂"""

    @staticmethod
    def create_client(
        cache_type: str,
        host: str,
        port: int
    ) -> CacheClient:
        """
        创建缓存客户端

        Args:
            cache_type: 缓存类型（redis、memcached）
            host: 主机地址
            port: 端口号

        Returns:
            缓存客户端实例
        """
        if cache_type.lower() == "redis":
            return RedisClient(host, port)
        elif cache_type.lower() == "memcached":
            return MemcachedClient(host, port)
        else:
            raise ValueError(f"Unsupported cache type: {cache_type}")

# 使用示例
redis_client = CacheClientFactory.create_client("redis", "localhost", 6379)
memcached_client = CacheClientFactory.create_client("memcached", "localhost", 11211)
```

---

### 2.3 装饰器模式

**装饰器模式**：动态地给一个对象添加一些额外的职责。

**应用场景**：为缓存操作添加日志、监控、重试等功能

**代码示例**：

```python
from functools import wraps
from typing import Callable, Any
import time
import logging

logger = logging.getLogger(__name__)

def log_decorator(func: Callable) -> Callable:
    """日志装饰器"""
    @wraps(func)
    def wrapper(*args, **kwargs) -> Any:
        logger.info(f"Calling {func.__name__} with args={args}, kwargs={kwargs}")
        try:
            result = func(*args, **kwargs)
            logger.info(f"{func.__name__} returned: {result}")
            return result
        except Exception as e:
            logger.error(f"{func.__name__} raised: {e}")
            raise
    return wrapper

def timing_decorator(func: Callable) -> Callable:
    """计时装饰器"""
    @wraps(func)
    def wrapper(*args, **kwargs) -> Any:
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            elapsed_time = time.time() - start_time
            logger.info(f"{func.__name__} took {elapsed_time:.3f}s")
            return result
        except Exception as e:
            elapsed_time = time.time() - start_time
            logger.error(f"{func.__name__} failed after {elapsed_time:.3f}s: {e}")
            raise
    return wrapper

def retry_decorator(max_attempts: int = 3):
    """重试装饰器"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            last_exception = None
            for attempt in range(1, max_attempts + 1):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_attempts:
                        logger.warning(f"Attempt {attempt} failed: {e}, retrying...")
                        time.sleep(1)
                    else:
                        logger.error(f"All {max_attempts} attempts failed")
            raise last_exception
        return wrapper
    return decorator

class Cache:
    """缓存类"""

    def __init__(self):
        self.cache = {}

    @log_decorator
    @timing_decorator
    @retry_decorator(max_attempts=3)
    def get(self, key: str) -> Any:
        """获取值"""
        if key not in self.cache:
            raise KeyError(f"Key not found: {key}")
        return self.cache[key]

    @log_decorator
    @timing_decorator
    def set(self, key: str, value: Any):
        """设置值"""
        self.cache[key] = value

# 使用示例
cache = Cache()
cache.set("key1", "value1")
value = cache.get("key1")  # 会记录日志、计时、重试
```

---

### 2.4 观察者模式

**观察者模式**：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知。

**应用场景**：缓存事件监听（命中、未命中、淘汰等）

**代码示例**：

```python
from abc import ABC, abstractmethod
from typing import List
from enum import Enum

class CacheEvent(Enum):
    """缓存事件类型"""
    HIT = "hit"
    MISS = "miss"
    EVICT = "evict"
    SET = "set"
    DELETE = "delete"

class CacheObserver(ABC):
    """缓存观察者接口"""

    @abstractmethod
    def on_event(self, event: CacheEvent, key: str, value: Any = None):
        """处理缓存事件"""
        pass

class CacheHitObserver(CacheObserver):
    """缓存命中观察者"""

    def __init__(self):
        self.hit_count = 0

    def on_event(self, event: CacheEvent, key: str, value: Any = None):
        if event == CacheEvent.HIT:
            self.hit_count += 1
            print(f"Cache hit: {key} (total hits: {self.hit_count})")

class CacheMissObserver(CacheObserver):
    """缓存未命中观察者"""

    def __init__(self):
        self.miss_count = 0

    def on_event(self, event: CacheEvent, key: str, value: Any = None):
        if event == CacheEvent.MISS:
            self.miss_count += 1
            print(f"Cache miss: {key} (total misses: {self.miss_count})")

class Cache:
    """缓存类（支持观察者模式）"""

    def __init__(self, capacity: int = 10):
        self.capacity = capacity
        self.cache = {}
        self.observers: List[CacheObserver] = []

    def add_observer(self, observer: CacheObserver):
        """添加观察者"""
        self.observers.append(observer)

    def remove_observer(self, observer: CacheObserver):
        """移除观察者"""
        if observer in self.observers:
            self.observers.remove(observer)

    def _notify_observers(self, event: CacheEvent, key: str, value: Any = None):
        """通知观察者"""
        for observer in self.observers:
            observer.on_event(event, key, value)

    def get(self, key: str) -> Any:
        """获取值"""
        if key in self.cache:
            self._notify_observers(CacheEvent.HIT, key)
            return self.cache[key]
        else:
            self._notify_observers(CacheEvent.MISS, key)
            return None

    def set(self, key: str, value: Any):
        """设置值"""
        if len(self.cache) >= self.capacity and key not in self.cache:
            # 淘汰一个key
            evicted_key = next(iter(self.cache))
            del self.cache[evicted_key]
            self._notify_observers(CacheEvent.EVICT, evicted_key)

        self.cache[key] = value
        self._notify_observers(CacheEvent.SET, key, value)

    def delete(self, key: str) -> bool:
        """删除值"""
        if key in self.cache:
            del self.cache[key]
            self._notify_observers(CacheEvent.DELETE, key)
            return True
        return False

# 使用示例
cache = Cache(capacity=3)
cache.add_observer(CacheHitObserver())
cache.add_observer(CacheMissObserver())

cache.set("a", 1)
cache.set("b", 2)
cache.set("c", 3)
cache.get("a")  # 命中
cache.get("d")  # 未命中
cache.set("e", 5)  # 淘汰c
```

---

## 3. 代码示例

### 3.1 缓存客户端

#### 3.1.1 Python实现

**完整的缓存客户端实现**：

```python
from typing import Optional, Any, Dict
import time
import threading
from collections import OrderedDict

class LRUCache:
    """LRU缓存实现"""

    def __init__(self, capacity: int):
        self.capacity = capacity
        self.cache = OrderedDict()
        self.lock = threading.RLock()

    def get(self, key: str) -> Optional[Any]:
        """获取值"""
        with self.lock:
            if key not in self.cache:
                return None

            # 移动到末尾（最近使用）
            value = self.cache.pop(key)
            self.cache[key] = value
            return value

    def set(self, key: str, value: Any, ttl: int = None):
        """设置值"""
        with self.lock:
            if key in self.cache:
                # 更新值
                self.cache.pop(key)
            elif len(self.cache) >= self.capacity:
                # 淘汰最久未使用的
                self.cache.popitem(last=False)

            self.cache[key] = {
                'value': value,
                'expire_time': time.time() + ttl if ttl else None
            }

    def delete(self, key: str) -> bool:
        """删除值"""
        with self.lock:
            if key in self.cache:
                del self.cache[key]
                return True
            return False

    def clear(self):
        """清空缓存"""
        with self.lock:
            self.cache.clear()

    def size(self) -> int:
        """获取缓存大小"""
        return len(self.cache)

    def _cleanup_expired(self):
        """清理过期项"""
        current_time = time.time()
        expired_keys = [
            key for key, item in self.cache.items()
            if item.get('expire_time') and item['expire_time'] < current_time
        ]
        for key in expired_keys:
            del self.cache[key]
```

---

#### 3.1.2 Golang实现

**LRU缓存实现（Go）**：

```go
package main

import (
    "container/list"
    "sync"
    "time"
)

type LRUCache struct {
    capacity int
    cache    map[string]*list.Element
    list     *list.List
    mutex    sync.RWMutex
}

type entry struct {
    key        string
    value      interface{}
    expireTime *time.Time
}

func NewLRUCache(capacity int) *LRUCache {
    return &LRUCache{
        capacity: capacity,
        cache:    make(map[string]*list.Element),
        list:     list.New(),
    }
}

func (lru *LRUCache) Get(key string) (interface{}, bool) {
    lru.mutex.Lock()
    defer lru.mutex.Unlock()

    if elem, ok := lru.cache[key]; ok {
        // 检查是否过期
        if elem.Value.(*entry).expireTime != nil {
            if time.Now().After(*elem.Value.(*entry).expireTime) {
                lru.removeElement(elem)
                return nil, false
            }
        }

        // 移动到末尾（最近使用）
        lru.list.MoveToBack(elem)
        return elem.Value.(*entry).value, true
    }

    return nil, false
}

func (lru *LRUCache) Set(key string, value interface{}, ttl time.Duration) {
    lru.mutex.Lock()
    defer lru.mutex.Unlock()

    if elem, ok := lru.cache[key]; ok {
        // 更新值
        elem.Value.(*entry).value = value
        if ttl > 0 {
            expireTime := time.Now().Add(ttl)
            elem.Value.(*entry).expireTime = &expireTime
        }
        lru.list.MoveToBack(elem)
    } else {
        // 检查容量
        if lru.list.Len() >= lru.capacity {
            // 淘汰最久未使用的
            front := lru.list.Front()
            if front != nil {
                lru.removeElement(front)
            }
        }

        // 添加新项
        var expireTime *time.Time
        if ttl > 0 {
            exp := time.Now().Add(ttl)
            expireTime = &exp
        }

        entry := &entry{
            key:        key,
            value:      value,
            expireTime: expireTime,
        }

        elem := lru.list.PushBack(entry)
        lru.cache[key] = elem
    }
}

func (lru *LRUCache) Delete(key string) bool {
    lru.mutex.Lock()
    defer lru.mutex.Unlock()

    if elem, ok := lru.cache[key]; ok {
        lru.removeElement(elem)
        return true
    }

    return false
}

func (lru *LRUCache) removeElement(elem *list.Element) {
    lru.list.Remove(elem)
    delete(lru.cache, elem.Value.(*entry).key)
}

func (lru *LRUCache) Size() int {
    lru.mutex.RLock()
    defer lru.mutex.RUnlock()
    return lru.list.Len()
}

// 使用示例
func main() {
    cache := NewLRUCache(3)

    cache.Set("a", 1, 0)
    cache.Set("b", 2, 0)
    cache.Set("c", 3, 0)

    value, ok := cache.Get("a")
    if ok {
        fmt.Println("Value:", value)
    }

    cache.Set("d", 4, 0) // 淘汰b
}
```

---

#### 3.1.3 Rust实现

**LRU缓存实现（Rust）**：

```rust
use std::collections::HashMap;
use std::sync::{Arc, RwLock};
use std::time::{Duration, Instant};

struct CacheEntry {
    value: String,
    expire_time: Option<Instant>,
}

pub struct LRUCache {
    capacity: usize,
    cache: Arc<RwLock<HashMap<String, CacheEntry>>>,
    access_order: Arc<RwLock<Vec<String>>>,
}

impl LRUCache {
    pub fn new(capacity: usize) -> Self {
        Self {
            capacity,
            cache: Arc::new(RwLock::new(HashMap::new())),
            access_order: Arc::new(RwLock::new(Vec::new())),
        }
    }

    pub fn get(&self, key: &str) -> Option<String> {
        let mut cache = self.cache.write().unwrap();
        let mut access_order = self.access_order.write().unwrap();

        if let Some(entry) = cache.get(key) {
            // 检查是否过期
            if let Some(expire_time) = entry.expire_time {
                if Instant::now() > expire_time {
                    cache.remove(key);
                    access_order.retain(|k| k != key);
                    return None;
                }
            }

            // 更新访问顺序
            access_order.retain(|k| k != key);
            access_order.push(key.to_string());

            Some(entry.value.clone())
        } else {
            None
        }
    }

    pub fn set(&self, key: &str, value: &str, ttl: Option<Duration>) {
        let mut cache = self.cache.write().unwrap();
        let mut access_order = self.access_order.write().unwrap();

        let expire_time = ttl.map(|d| Instant::now() + d);

        if cache.contains_key(key) {
            // 更新值
            cache.insert(
                key.to_string(),
                CacheEntry {
                    value: value.to_string(),
                    expire_time,
                },
            );
            access_order.retain(|k| k != key);
            access_order.push(key.to_string());
        } else {
            // 检查容量
            if cache.len() >= self.capacity {
                // 淘汰最久未使用的
                if let Some(oldest_key) = access_order.first() {
                    cache.remove(oldest_key);
                    access_order.remove(0);
                }
            }

            // 添加新项
            cache.insert(
                key.to_string(),
                CacheEntry {
                    value: value.to_string(),
                    expire_time,
                },
            );
            access_order.push(key.to_string());
        }
    }

    pub fn delete(&self, key: &str) -> bool {
        let mut cache = self.cache.write().unwrap();
        let mut access_order = self.access_order.write().unwrap();

        if cache.remove(key).is_some() {
            access_order.retain(|k| k != key);
            true
        } else {
            false
        }
    }

    pub fn size(&self) -> usize {
        self.cache.read().unwrap().len()
    }
}

// 使用示例
fn main() {
    let cache = LRUCache::new(3);

    cache.set("a", "1", None);
    cache.set("b", "2", None);
    cache.set("c", "3", None);

    if let Some(value) = cache.get("a") {
        println!("Value: {}", value);
    }

    cache.set("d", "4", None); // 淘汰b
}
```

---

#### 3.1.4 C++实现

**LRU缓存实现（C++）**：

```cpp
#include <unordered_map>
#include <list>
#include <mutex>
#include <chrono>
#include <optional>

template<typename Key, typename Value>
class LRUCache {
private:
    struct Entry {
        Value value;
        std::optional<std::chrono::steady_clock::time_point> expire_time;
    };

    size_t capacity_;
    std::unordered_map<Key, typename std::list<std::pair<Key, Entry>>::iterator> cache_;
    std::list<std::pair<Key, Entry>> items_;
    std::mutex mutex_;

    void removeLRU() {
        if (!items_.empty()) {
            auto last = items_.back();
            cache_.erase(last.first);
            items_.pop_back();
        }
    }

    bool isExpired(const Entry& entry) const {
        if (entry.expire_time.has_value()) {
            return std::chrono::steady_clock::now() > entry.expire_time.value();
        }
        return false;
    }

public:
    explicit LRUCache(size_t capacity) : capacity_(capacity) {}

    std::optional<Value> Get(const Key& key) {
        std::lock_guard<std::mutex> lock(mutex_);

        auto it = cache_.find(key);
        if (it == cache_.end()) {
            return std::nullopt;
        }

        auto& entry = it->second->second;

        // 检查是否过期
        if (isExpired(entry)) {
            items_.erase(it->second);
            cache_.erase(it);
            return std::nullopt;
        }

        // 移动到末尾（最近使用）
        items_.splice(items_.end(), items_, it->second);

        return entry.value;
    }

    void Set(const Key& key, const Value& value,
             std::optional<std::chrono::seconds> ttl = std::nullopt) {
        std::lock_guard<std::mutex> lock(mutex_);

        auto it = cache_.find(key);
        if (it != cache_.end()) {
            // 更新值
            it->second->second.value = value;
            if (ttl.has_value()) {
                it->second->second.expire_time =
                    std::chrono::steady_clock::now() + ttl.value();
            }
            items_.splice(items_.end(), items_, it->second);
        } else {
            // 检查容量
            if (items_.size() >= capacity_) {
                removeLRU();
            }

            // 添加新项
            Entry entry{value, std::nullopt};
            if (ttl.has_value()) {
                entry.expire_time = std::chrono::steady_clock::now() + ttl.value();
            }

            items_.emplace_back(key, entry);
            cache_[key] = std::prev(items_.end());
        }
    }

    bool Delete(const Key& key) {
        std::lock_guard<std::mutex> lock(mutex_);

        auto it = cache_.find(key);
        if (it != cache_.end()) {
            items_.erase(it->second);
            cache_.erase(it);
            return true;
        }
        return false;
    }

    size_t Size() const {
        std::lock_guard<std::mutex> lock(mutex_);
        return items_.size();
    }
};

// 使用示例
#include <iostream>

int main() {
    LRUCache<std::string, int> cache(3);

    cache.Set("a", 1);
    cache.Set("b", 2);
    cache.Set("c", 3);

    auto value = cache.Get("a");
    if (value.has_value()) {
        std::cout << "Value: " << value.value() << std::endl;
    }

    cache.Set("d", 4); // 淘汰b

    return 0;
}
```

---

### 3.2 连接池

#### 3.2.1 Python实现

**连接池实现**：

```python
from typing import List, Optional
import threading
import time
from queue import Queue, Empty

class Connection:
    """连接类"""

    def __init__(self, connection_id: str):
        self.connection_id = connection_id
        self.created_at = time.time()
        self.last_used = time.time()

    def execute(self, command: str) -> str:
        """执行命令"""
        self.last_used = time.time()
        return f"Result of {command}"

class ConnectionPool:
    """连接池"""

    def __init__(
        self,
        min_size: int = 5,
        max_size: int = 20,
        idle_timeout: int = 300
    ):
        self.min_size = min_size
        self.max_size = max_size
        self.idle_timeout = idle_timeout
        self.pool: Queue = Queue(maxsize=max_size)
        self.active_connections = 0
        self.lock = threading.Lock()
        self._initialize_pool()

    def _initialize_pool(self):
        """初始化连接池"""
        for i in range(self.min_size):
            conn = Connection(f"conn_{i}")
            self.pool.put(conn)

    def get_connection(self, timeout: float = 5.0) -> Optional[Connection]:
        """获取连接"""
        try:
            # 尝试从池中获取
            conn = self.pool.get(timeout=timeout)

            # 检查连接是否过期
            if time.time() - conn.last_used > self.idle_timeout:
                # 连接过期，创建新连接
                conn = self._create_connection()

            with self.lock:
                self.active_connections += 1

            return conn
        except Empty:
            # 池为空，尝试创建新连接
            with self.lock:
                if self.active_connections < self.max_size:
                    conn = self._create_connection()
                    self.active_connections += 1
                    return conn
            return None

    def return_connection(self, conn: Connection):
        """归还连接"""
        with self.lock:
            self.active_connections -= 1

        # 检查连接是否过期
        if time.time() - conn.last_used > self.idle_timeout:
            return  # 连接过期，不归还

        try:
            self.pool.put_nowait(conn)
        except:
            pass  # 池已满，丢弃连接

    def _create_connection(self) -> Connection:
        """创建新连接"""
        conn_id = f"conn_{int(time.time() * 1000)}"
        return Connection(conn_id)

    def close(self):
        """关闭连接池"""
        while not self.pool.empty():
            try:
                self.pool.get_nowait()
            except:
                break

# 使用示例
pool = ConnectionPool(min_size=5, max_size=20)

# 获取连接
conn = pool.get_connection()
if conn:
    result = conn.execute("GET key1")
    pool.return_connection(conn)
```

---

#### 3.2.2 Golang实现

**连接池实现（Go）**：

```go
package main

import (
    "sync"
    "time"
)

type Connection struct {
    ID        string
    CreatedAt time.Time
    LastUsed  time.Time
}

func (c *Connection) Execute(command string) string {
    c.LastUsed = time.Now()
    return "Result of " + command
}

type ConnectionPool struct {
    minSize          int
    maxSize          int
    idleTimeout      time.Duration
    pool             chan *Connection
    activeCount      int
    mutex            sync.Mutex
    connectionFactory func() *Connection
}

func NewConnectionPool(minSize, maxSize int, idleTimeout time.Duration) *ConnectionPool {
    pool := &ConnectionPool{
        minSize:     minSize,
        maxSize:     maxSize,
        idleTimeout: idleTimeout,
        pool:        make(chan *Connection, maxSize),
        connectionFactory: func() *Connection {
            return &Connection{
                ID:        generateID(),
                CreatedAt: time.Now(),
                LastUsed:  time.Now(),
            }
        },
    }

    pool.initialize()
    return pool
}

func (p *ConnectionPool) initialize() {
    for i := 0; i < p.minSize; i++ {
        p.pool <- p.connectionFactory()
    }
}

func (p *ConnectionPool) GetConnection(timeout time.Duration) (*Connection, error) {
    select {
    case conn := <-p.pool:
        // 检查连接是否过期
        if time.Since(conn.LastUsed) > p.idleTimeout {
            conn = p.connectionFactory()
        }

        p.mutex.Lock()
        p.activeCount++
        p.mutex.Unlock()

        return conn, nil
    case <-time.After(timeout):
        // 尝试创建新连接
        p.mutex.Lock()
        if p.activeCount < p.maxSize {
            p.activeCount++
            p.mutex.Unlock()
            return p.connectionFactory(), nil
        }
        p.mutex.Unlock()
        return nil, ErrPoolExhausted
    }
}

func (p *ConnectionPool) ReturnConnection(conn *Connection) {
    p.mutex.Lock()
    p.activeCount--
    p.mutex.Unlock()

    // 检查连接是否过期
    if time.Since(conn.LastUsed) > p.idleTimeout {
        return
    }

    select {
    case p.pool <- conn:
    default:
        // 池已满，丢弃连接
    }
}

func generateID() string {
    return fmt.Sprintf("conn_%d", time.Now().UnixNano())
}

var ErrPoolExhausted = errors.New("connection pool exhausted")

// 使用示例
func main() {
    pool := NewConnectionPool(5, 20, 5*time.Minute)

    conn, err := pool.GetConnection(5 * time.Second)
    if err != nil {
        // 处理错误
        return
    }

    result := conn.Execute("GET key1")
    pool.ReturnConnection(conn)

    fmt.Println("Result:", result)
}
```

---

#### 3.2.3 Rust实现

**连接池实现（Rust）**：

```rust
use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant};
use std::collections::VecDeque;

struct Connection {
    id: String,
    created_at: Instant,
    last_used: Instant,
}

impl Connection {
    fn new(id: String) -> Self {
        let now = Instant::now();
        Self {
            id,
            created_at: now,
            last_used: now,
        }
    }

    fn execute(&mut self, command: &str) -> String {
        self.last_used = Instant::now();
        format!("Result of {}", command)
    }
}

pub struct ConnectionPool {
    min_size: usize,
    max_size: usize,
    idle_timeout: Duration,
    pool: Arc<Mutex<VecDeque<Arc<Mutex<Connection>>>>>,
    active_count: Arc<Mutex<usize>>,
}

impl ConnectionPool {
    pub fn new(min_size: usize, max_size: usize, idle_timeout: Duration) -> Self {
        let pool = Arc::new(Mutex::new(VecDeque::new()));

        // 初始化连接池
        {
            let mut p = pool.lock().unwrap();
            for i in 0..min_size {
                let conn = Arc::new(Mutex::new(Connection::new(
                    format!("conn_{}", i)
                )));
                p.push_back(conn);
            }
        }

        Self {
            min_size,
            max_size,
            idle_timeout,
            pool,
            active_count: Arc::new(Mutex::new(0)),
        }
    }

    pub fn get_connection(&self, timeout: Duration) -> Option<Arc<Mutex<Connection>>> {
        let mut pool = self.pool.lock().unwrap();

        // 尝试从池中获取
        if let Some(conn) = pool.pop_front() {
            let mut conn_guard = conn.lock().unwrap();

            // 检查连接是否过期
            if conn_guard.last_used.elapsed() > self.idle_timeout {
                drop(conn_guard);
                // 创建新连接
                return self.create_new_connection();
            }

            drop(conn_guard);
            *self.active_count.lock().unwrap() += 1;
            return Some(conn);
        }

        // 池为空，尝试创建新连接
        drop(pool);
        self.create_new_connection()
    }

    fn create_new_connection(&self) -> Option<Arc<Mutex<Connection>>> {
        let mut active_count = self.active_count.lock().unwrap();

        if *active_count < self.max_size {
            *active_count += 1;
            let conn = Arc::new(Mutex::new(Connection::new(
                format!("conn_{}", Instant::now().elapsed().as_nanos())
            )));
            return Some(conn);
        }

        None
    }

    pub fn return_connection(&self, conn: Arc<Mutex<Connection>>) {
        *self.active_count.lock().unwrap() -= 1;

        let conn_guard = conn.lock().unwrap();

        // 检查连接是否过期
        if conn_guard.last_used.elapsed() > self.idle_timeout {
            return;
        }

        drop(conn_guard);

        let mut pool = self.pool.lock().unwrap();
        if pool.len() < self.max_size {
            pool.push_back(conn);
        }
    }
}

// 使用示例
fn main() {
    let pool = ConnectionPool::new(5, 20, Duration::from_secs(300));

    if let Some(conn) = pool.get_connection(Duration::from_secs(5)) {
        let result = conn.lock().unwrap().execute("GET key1");
        pool.return_connection(conn);
        println!("Result: {}", result);
    }
}
```

---

### 3.3 监控工具

#### 3.3.1 Python实现

**监控工具实现**：

```python
from typing import Dict, List
from collections import defaultdict, deque
from datetime import datetime, timedelta
import threading

class CacheMetrics:
    """缓存指标"""

    def __init__(self, window_size: int = 60):
        """
        初始化指标

        Args:
            window_size: 时间窗口大小（秒）
        """
        self.window_size = window_size
        self.hits = deque()
        self.misses = deque()
        self.latencies = deque()
        self.errors = deque()
        self.lock = threading.Lock()

    def record_hit(self):
        """记录命中"""
        with self.lock:
            self.hits.append(datetime.now())
            self._cleanup_old_records()

    def record_miss(self):
        """记录未命中"""
        with self.lock:
            self.misses.append(datetime.now())
            self._cleanup_old_records()

    def record_latency(self, latency: float):
        """记录延迟"""
        with self.lock:
            self.latencies.append((datetime.now(), latency))
            self._cleanup_old_records()

    def record_error(self, error: Exception):
        """记录错误"""
        with self.lock:
            self.errors.append((datetime.now(), str(error)))
            self._cleanup_old_records()

    def _cleanup_old_records(self):
        """清理过期记录"""
        cutoff = datetime.now() - timedelta(seconds=self.window_size)

        while self.hits and self.hits[0] < cutoff:
            self.hits.popleft()

        while self.misses and self.misses[0] < cutoff:
            self.misses.popleft()

        while self.latencies and self.latencies[0][0] < cutoff:
            self.latencies.popleft()

        while self.errors and self.errors[0][0] < cutoff:
            self.errors.popleft()

    def get_hit_rate(self) -> float:
        """获取命中率"""
        with self.lock:
            total = len(self.hits) + len(self.misses)
            if total == 0:
                return 0.0
            return len(self.hits) / total

    def get_avg_latency(self) -> float:
        """获取平均延迟"""
        with self.lock:
            if not self.latencies:
                return 0.0
            return sum(latency for _, latency in self.latencies) / len(self.latencies)

    def get_error_rate(self) -> float:
        """获取错误率"""
        with self.lock:
            total = len(self.hits) + len(self.misses) + len(self.errors)
            if total == 0:
                return 0.0
            return len(self.errors) / total

    def get_stats(self) -> Dict:
        """获取统计信息"""
        return {
            'hit_rate': self.get_hit_rate(),
            'avg_latency': self.get_avg_latency(),
            'error_rate': self.get_error_rate(),
            'total_hits': len(self.hits),
            'total_misses': len(self.misses),
            'total_errors': len(self.errors)
        }

# 使用示例
metrics = CacheMetrics(window_size=60)

# 记录操作
metrics.record_hit()
metrics.record_miss()
metrics.record_latency(0.001)
metrics.record_error(Exception("Test error"))

# 获取统计信息
stats = metrics.get_stats()
print(f"Hit rate: {stats['hit_rate']:.2%}")
print(f"Avg latency: {stats['avg_latency']:.3f}s")
print(f"Error rate: {stats['error_rate']:.2%}")
```

---

#### 3.3.2 Golang实现

**监控工具实现（Go）**：

```go
package main

import (
    "sync"
    "time"
)

type MetricPoint struct {
    Time  time.Time
    Value float64
}

type CacheMetrics struct {
    windowSize time.Duration
    hits       []time.Time
    misses     []time.Time
    latencies  []MetricPoint
    errors     []MetricPoint
    mutex      sync.RWMutex
}

func NewCacheMetrics(windowSize time.Duration) *CacheMetrics {
    return &CacheMetrics{
        windowSize: windowSize,
        hits:       make([]time.Time, 0),
        misses:     make([]time.Time, 0),
        latencies:  make([]MetricPoint, 0),
        errors:      make([]MetricPoint, 0),
    }
}

func (m *CacheMetrics) RecordHit() {
    m.mutex.Lock()
    defer m.mutex.Unlock()

    m.hits = append(m.hits, time.Now())
    m.cleanup()
}

func (m *CacheMetrics) RecordMiss() {
    m.mutex.Lock()
    defer m.mutex.Unlock()

    m.misses = append(m.misses, time.Now())
    m.cleanup()
}

func (m *CacheMetrics) RecordLatency(latency float64) {
    m.mutex.Lock()
    defer m.mutex.Unlock()

    m.latencies = append(m.latencies, MetricPoint{
        Time:  time.Now(),
        Value: latency,
    })
    m.cleanup()
}

func (m *CacheMetrics) cleanup() {
    cutoff := time.Now().Add(-m.windowSize)

    // 清理hits
    i := 0
    for _, hit := range m.hits {
        if hit.After(cutoff) {
            m.hits[i] = hit
            i++
        }
    }
    m.hits = m.hits[:i]

    // 清理misses
    i = 0
    for _, miss := range m.misses {
        if miss.After(cutoff) {
            m.misses[i] = miss
            i++
        }
    }
    m.misses = m.misses[:i]

    // 清理latencies
    i = 0
    for _, latency := range m.latencies {
        if latency.Time.After(cutoff) {
            m.latencies[i] = latency
            i++
        }
    }
    m.latencies = m.latencies[:i]

    // 清理errors
    i = 0
    for _, err := range m.errors {
        if err.Time.After(cutoff) {
            m.errors[i] = err
            i++
        }
    }
    m.errors = m.errors[:i]
}

func (m *CacheMetrics) GetHitRate() float64 {
    m.mutex.RLock()
    defer m.mutex.RUnlock()

    total := len(m.hits) + len(m.misses)
    if total == 0 {
        return 0.0
    }
    return float64(len(m.hits)) / float64(total)
}

func (m *CacheMetrics) GetAvgLatency() float64 {
    m.mutex.RLock()
    defer m.mutex.RUnlock()

    if len(m.latencies) == 0 {
        return 0.0
    }

    sum := 0.0
    for _, latency := range m.latencies {
        sum += latency.Value
    }
    return sum / float64(len(m.latencies))
}

func (m *CacheMetrics) GetErrorRate() float64 {
    m.mutex.RLock()
    defer m.mutex.RUnlock()

    total := len(m.hits) + len(m.misses) + len(m.errors)
    if total == 0 {
        return 0.0
    }
    return float64(len(m.errors)) / float64(total)
}

type Stats struct {
    HitRate    float64
    AvgLatency float64
    ErrorRate  float64
    TotalHits  int
    TotalMisses int
    TotalErrors int
}

func (m *CacheMetrics) GetStats() Stats {
    m.mutex.RLock()
    defer m.mutex.RUnlock()

    return Stats{
        HitRate:     m.GetHitRate(),
        AvgLatency:  m.GetAvgLatency(),
        ErrorRate:   m.GetErrorRate(),
        TotalHits:   len(m.hits),
        TotalMisses: len(m.misses),
        TotalErrors: len(m.errors),
    }
}

// 使用示例
func main() {
    metrics := NewCacheMetrics(60 * time.Second)

    metrics.RecordHit()
    metrics.RecordMiss()
    metrics.RecordLatency(0.001)

    stats := metrics.GetStats()
    fmt.Printf("Hit rate: %.2f%%\n", stats.HitRate*100)
    fmt.Printf("Avg latency: %.3fs\n", stats.AvgLatency)
    fmt.Printf("Error rate: %.2f%%\n", stats.ErrorRate*100)
}
```

---

## 4. 最佳实践

### 4.1 代码组织

1. **模块化设计**：将功能拆分为独立的模块
2. **分层架构**：使用分层架构组织代码
3. **依赖注入**：使用依赖注入管理依赖关系
4. **配置管理**：集中管理配置信息

### 4.2 错误处理

见[异常处理模式](./02.06.02-异常处理模式.md)。

### 4.3 性能优化

1. **连接池**：使用连接池复用连接
2. **批量操作**：使用批量操作减少网络往返
3. **异步处理**：使用异步处理提高并发性能
4. **缓存预热**：预热缓存提高命中率

---

## 5. 测试策略

### 5.1 单元测试

**单元测试示例**：

```python
import unittest

class TestLRUCache(unittest.TestCase):
    """LRU缓存测试"""

    def setUp(self):
        self.cache = LRUCache(capacity=3)

    def test_get_set(self):
        """测试get和set"""
        self.cache.set("a", 1)
        self.assertEqual(self.cache.get("a"), 1)

    def test_eviction(self):
        """测试淘汰"""
        self.cache.set("a", 1)
        self.cache.set("b", 2)
        self.cache.set("c", 3)
        self.cache.set("d", 4)  # 应该淘汰a
        self.assertIsNone(self.cache.get("a"))
        self.assertEqual(self.cache.get("d"), 4)

    def test_lru_order(self):
        """测试LRU顺序"""
        self.cache.set("a", 1)
        self.cache.set("b", 2)
        self.cache.set("c", 3)
        self.cache.get("a")  # 访问a
        self.cache.set("d", 4)  # 应该淘汰b
        self.assertIsNone(self.cache.get("b"))
        self.assertEqual(self.cache.get("a"), 1)

if __name__ == '__main__':
    unittest.main()
```

### 5.2 集成测试

**集成测试**：测试多个组件协同工作。

### 5.3 压力测试

**压力测试**：测试系统在高负载下的表现。

---

## 6. 扩展阅读

- [容错机制设计](./02.06.01-容错机制设计.md)
- [异常处理模式](./02.06.02-异常处理模式.md)
- [系统动态特征](../../05-全栈分析/05.06-系统动态特征/README.md)

---

## 7. 权威参考

### 7.1 学术论文

1. **"Design Patterns: Elements of Reusable Object-Oriented Software"** - Gang of Four, 1994

### 7.2 官方文档

1. **"Python Design Patterns"** - Python Documentation
   - URL: <https://docs.python.org/3/>

### 7.3 经典书籍

1. **《设计模式：可复用面向对象软件的基础》** - GoF, 机械工业出版社, 2019
   - ISBN: 978-7111213826

---

**文档版本**：v1.0
**最后更新**：2025-01
**文档状态**：✅ 完成
