# 03.03.02 Sentinel哨兵机制

## 目录

- [03.03.02 Sentinel哨兵机制](#030302-sentinel哨兵机制)
  - [目录](#目录)
  - [1. 概述](#1-概述)
    - [1.1 定义与历史背景](#11-定义与历史背景)
    - [1.2 应用价值](#12-应用价值)
  - [2. 核心功能](#2-核心功能)
    - [2.1 主要功能](#21-主要功能)
    - [2.2 形式化定义](#22-形式化定义)
  - [3. 架构设计](#3-架构设计)
    - [3.1 最小高可用配置](#31-最小高可用配置)
    - [3.2 Sentinel通信](#32-sentinel通信)
  - [4. 故障检测机制](#4-故障检测机制)
    - [4.1 主观下线（SDOWN）](#41-主观下线sdown)
    - [4.2 客观下线（ODOWN）](#42-客观下线odown)
  - [5. 故障转移机制](#5-故障转移机制)
    - [5.1 故障转移流程](#51-故障转移流程)
      - [5.1.1 领导者选举](#511-领导者选举)
      - [5.1.2 选择新主节点](#512-选择新主节点)
      - [5.1.3 故障转移执行](#513-故障转移执行)
    - [5.2 Leader选举](#52-leader选举)
  - [6. 性能分析](#6-性能分析)
    - [6.1 故障转移时间分析](#61-故障转移时间分析)
    - [6.2 可用性分析](#62-可用性分析)
  - [7. 配置与使用](#7-配置与使用)
    - [7.1 Sentinel配置文件](#71-sentinel配置文件)
    - [7.2 启动Sentinel](#72-启动sentinel)
    - [7.3 客户端集成](#73-客户端集成)
  - [8. 适用场景](#8-适用场景)
    - [8.1 优势场景](#81-优势场景)
    - [8.2 不适用场景](#82-不适用场景)
  - [9. 扩展阅读](#9-扩展阅读)
  - [10. 权威参考](#10-权威参考)
    - [10.1 官方文档](#101-官方文档)
    - [10.2 经典书籍](#102-经典书籍)
    - [10.3 学术论文](#103-学术论文)
    - [10.4 在线资源](#104-在线资源)

---

## 1. 概述

### 1.1 定义与历史背景

**Sentinel（哨兵）**是Redis的高可用解决方案，通过监控主从节点状态，自动进行故障检测和故障转移，实现Redis的高可用。

**历史发展**：

- **2012年**：Redis 2.6引入Sentinel
- **2015年**：Redis 3.0优化Sentinel实现
- **2020年代**：Sentinel成为Redis高可用的标准方案

### 1.2 应用价值

Sentinel在Redis中具有重要价值：

1. **自动故障转移**：主节点故障时自动切换
2. **高可用性**：保证服务持续可用
3. **监控告警**：实时监控节点状态
4. **配置管理**：自动更新客户端配置

## 2. 核心功能

### 2.1 主要功能

1. **监控**：持续监控主从节点是否正常工作
2. **通知**：当被监控节点出现问题时，通知管理员
3. **自动故障转移**：主节点故障时，自动将某个从节点升级为主节点
4. **配置提供者**：客户端连接时，返回当前主节点地址

### 2.2 形式化定义

设Sentinel集合为$S = \{s_1, s_2, ..., s_n\}$，主节点为$M$，从节点集合为$Slaves = \{sl_1, sl_2, ..., sl_m\}$。

**故障检测**：

$$
DetectFailure(M) = \begin{cases}
\text{SDOWN} & \text{如果单个Sentinel认为M不可达} \\
\text{ODOWN} & \text{如果超过}\lceil \frac{n}{2} \rceil\text{个Sentinel认为M不可达}
\end{cases}
$$

**故障转移**：

$$
Failover(M) = \begin{cases}
\text{选举Leader} & \text{如果ODOWN} \\
\text{选择新主节点} & \text{从Slaves中选择最优节点} \\
\text{切换} & \text{将新主节点升级为主节点}
\end{cases}
$$

## 3. 架构设计

### 3.1 最小高可用配置

```
┌─────────────┐
│  Sentinel1  │
│   (监控)    │
└─────────────┘
      │
      │ 监控
      │
┌─────────────┐         ┌─────────────┐
│   Master    │────────│   Slave1    │
│  (主节点)   │         │  (从节点)   │
└─────────────┘         └─────────────┘
      │
      │ 监控
      │
┌─────────────┐         ┌─────────────┐
│  Sentinel2  │         │   Slave2    │
│   (监控)    │         │  (从节点)   │
└─────────────┘         └─────────────┘
      │
      │ 监控
      │
┌─────────────┐
│  Sentinel3  │
│   (监控)    │
└─────────────┘
```

**最小配置**：3个Sentinel实例（满足超过50%存活要求）

**定理 3.1**：最小Sentinel数量为3，满足超过50%存活要求。

**证明**：

- 需要超过50%的Sentinel存活才能进行故障转移
- 3个Sentinel：需要至少2个存活（$\lceil \frac{3}{2} \rceil = 2$）
- 可以容忍1个Sentinel故障
- 如果只有2个Sentinel：需要至少2个存活，无法容忍任何故障

### 3.2 Sentinel通信

**Sentinel通信机制**：

- Sentinel之间通过Pub/Sub通信
- 使用`__sentinel__:hello`频道发布信息
- 定期发送PING命令检测节点状态

## 4. 故障检测机制

### 4.1 主观下线（SDOWN）

```c
// 单个Sentinel认为节点不可达
void sentinelCheckSubjectivelyDown(sentinelRedisInstance *ri) {
    mstime_t elapsed = mstime() - ri->last_avail_time;

    if (elapsed > ri->down_after_period) {
        // 超过down_after_period时间未响应
        if ((ri->flags & SRI_S_DOWN) == 0) {
            sentinelEvent(LL_WARNING, "+sdown", ri, "%@");
            ri->flags |= SRI_S_DOWN;
        }
    } else {
        // 节点恢复
        if (ri->flags & SRI_S_DOWN) {
            sentinelEvent(LL_WARNING, "-sdown", ri, "%@");
            ri->flags &= ~SRI_S_DOWN;
        }
    }
}
```

**触发条件**：

- `down-after-milliseconds`时间内未收到PING响应
- 默认值：5000ms

**定理 4.1**：主观下线的时间复杂度为O(1)。

**证明**：

- 检查节点响应时间：O(1)
- 更新节点状态：O(1)
- 总时间复杂度：O(1)

### 4.2 客观下线（ODOWN）

```c
// 超过quorum个Sentinel认为节点不可达
int sentinelCheckObjectivelyDown(sentinelRedisInstance *master) {
    unsigned int quorum = master->quorum;
    unsigned int odown_quorum = 1; // 至少需要1个Sentinel

    if (master->flags & SRI_S_DOWN) {
        // 统计认为主节点下线的Sentinel数量
        unsigned int masters = 0;
        dictIterator *di;
        dictEntry *de;

        di = dictGetIterator(master->sentinels);
        while((de = dictNext(di)) != NULL) {
            sentinelRedisInstance *ri = dictGetVal(de);
            if (ri->flags & SRI_MASTER_DOWN) {
                masters++;
            }
        }
        dictReleaseIterator(di);

        // 检查是否达到quorum
        if (masters >= quorum) {
            if ((master->flags & SRI_O_DOWN) == 0) {
                sentinelEvent(LL_WARNING, "+odown", master,
                            "%quorum %d/%d", masters, quorum);
                master->flags |= SRI_O_DOWN;
            }
            return 1;
        }
    }

    // 恢复
    if (master->flags & SRI_O_DOWN) {
        sentinelEvent(LL_WARNING, "-odown", master, "%@");
        master->flags &= ~SRI_O_DOWN;
    }
    return 0;
}
```

**触发条件**：

- 超过`quorum`个Sentinel认为主节点下线
- 默认quorum：1（至少需要1个Sentinel）

## 5. 故障转移机制

### 5.1 故障转移流程

**故障转移阶段**：

1. **WAIT_START**：等待开始，选举Leader
2. **SELECT_SLAVE**：选择最优从节点
3. **SEND_SLAVEOF_NOONE**：发送SLAVEOF NO ONE命令
4. **WAIT_PROMOTION**：等待从节点提升为主节点
5. **RECONF_SLAVES**：重新配置其他从节点

#### 5.1.1 领导者选举

```c
// Raft算法变种选举
void sentinelStartFailoverIfNeeded(sentinelRedisInstance *master) {
    // 检查是否需要进行故障转移
    if (master->flags & SRI_FAILOVER_IN_PROGRESS) return;
    if (master->flags & SRI_PROMOTED) return;

    // 检查客观下线
    if (!(master->flags & SRI_O_DOWN)) return;

    // 检查故障转移延迟
    if (mstime() - master->last_avail_time < master->failover_timeout) {
        return;
    }

    // 检查是否已经有其他Sentinel在故障转移
    if (sentinelGetLeader(master) != sentinel.myid) {
        return;
    }

    // 开始故障转移
    sentinelStartFailover(master);
}

// 选举领导者
char *sentinelGetLeader(sentinelRedisInstance *master, uint64_t *leader_epoch) {
    dict *counters = dictCreate(&leaderVoteDictType, NULL);
    dictIterator *di;
    dictEntry *de;
    unsigned int voters = 0, voters_quorum;
    char *myvote;
    char *winner = NULL;
    uint64_t max_epoch = 0;
    uint64_t epoch;

    voters_quorum = (sentinelNumMasters(master) / 2) + 1;

    // 收集投票
    di = dictGetIterator(master->sentinels);
    while((de = dictNext(di)) != NULL) {
        sentinelRedisInstance *ri = dictGetVal(de);
        if (ri->leader != NULL && ri->leader_epoch == sentinel.current_epoch) {
            epoch = ri->leader_epoch;
            uint64_t *count = dictFetchValue(counters, ri->leader);
            if (count) {
                (*count)++;
            } else {
                uint64_t c = 1;
                dictAdd(counters, ri->leader, &c);
            }
            if (epoch > max_epoch) max_epoch = epoch;
        }
    }
    dictReleaseIterator(di);

    // 统计投票
    di = dictGetIterator(counters);
    while((de = dictNext(di)) != NULL) {
        uint64_t *count = dictGetVal(de);
        voters += *count;
        if (*count >= voters_quorum) {
            winner = dictGetKey(de);
            break;
        }
    }
    dictReleaseIterator(di);

    if (leader_epoch) *leader_epoch = max_epoch;
    dictRelease(counters);
    return winner;
}
```

**定理 5.1**：Leader选举使用Raft算法变种，需要超过50%的Sentinel投票。

**证明**：

- 需要超过50%的Sentinel投票才能成为Leader
- 3个Sentinel：需要至少2个投票（$\lceil \frac{3}{2} \rceil = 2$）
- 保证只有一个Leader被选出

#### 5.1.2 选择新主节点

```c
// 选择最优从节点作为新主节点
sentinelRedisInstance *sentinelSelectSlave(sentinelRedisInstance *master) {
    sentinelRedisInstance **instance = zmalloc(sizeof(instance[0]) *
                                               dictSize(master->slaves));
    int numslaves = 0, j;
    dictIterator *di;
    dictEntry *de;
    mstime_t max_master_down_time = 0;

    // 收集所有从节点
    di = dictGetIterator(master->slaves);
    while((de = dictNext(di)) != NULL) {
        sentinelRedisInstance *slave = dictGetVal(de);
        mstime_t info_validity_time;

        // 检查从节点状态
        if (slave->flags & (SRI_S_DOWN | SRI_O_DOWN)) continue;
        if (slave->link->disconnected) continue;
        if (slave->role_reported != SRI_SLAVE) continue;

        // 检查主从断开时间
        info_validity_time = mstime() - slave->info_refresh;
        if (info_validity_time > SENTINEL_PING_PERIOD * 5) continue;

        // 检查从节点优先级
        if (slave->slave_priority == 0) continue;

        instance[numslaves++] = slave;
        if (slave->master_link_down_time > max_master_down_time)
            max_master_down_time = slave->master_link_down_time;
    }
    dictReleaseIterator(di);

    if (numslaves == 0) return NULL;

    // 排序：优先级 > 复制偏移量 > runid
    qsort(instance, numslaves, sizeof(sentinelRedisInstance*),
          compareSlavesForPromotion);

    return instance[0];
}

// 比较函数
int compareSlavesForPromotion(const void *a, const void *b) {
    sentinelRedisInstance **sa = (sentinelRedisInstance **)a;
    sentinelRedisInstance **sb = (sentinelRedisInstance **)b;

    // 1. 优先级（越小越好）
    if ((*sa)->slave_priority != (*sb)->slave_priority)
        return (*sa)->slave_priority - (*sb)->slave_priority;

    // 2. 复制偏移量（越大越好）
    if ((*sa)->slave_repl_offset > (*sb)->slave_repl_offset) return -1;
    if ((*sa)->slave_repl_offset < (*sb)->slave_repl_offset) return 1;

    // 3. runid（字典序）
    return strcmp((*sa)->runid, (*sb)->runid);
}
```

**选择标准**：

1. **优先级**：优先级越小越好（slave-priority）
2. **复制偏移量**：偏移量越大越好（数据最新）
3. **runid**：字典序最小

**定理 5.2**：选择新主节点的时间复杂度为O(m log m)，其中m为从节点数。

**证明**：

- 收集从节点：O(m)
- 排序：O(m log m)
- 总时间复杂度：O(m log m)

#### 5.1.3 故障转移执行

```c
// 执行故障转移
void sentinelFailoverStateMachine(sentinelRedisInstance *ri) {
    serverAssert(ri->flags & SRI_MASTER);

    if (!(ri->flags & SRI_FAILOVER_IN_PROGRESS)) return;

    switch(ri->failover_state) {
        case SENTINEL_FAILOVER_STATE_WAIT_START:
            sentinelFailoverWaitStart(ri);
            break;

        case SENTINEL_FAILOVER_STATE_SELECT_SLAVE:
            sentinelFailoverSelectSlave(ri);
            break;

        case SENTINEL_FAILOVER_STATE_SEND_SLAVEOF_NOONE:
            sentinelFailoverSendSlaveOfNoOne(ri);
            break;

        case SENTINEL_FAILOVER_STATE_WAIT_PROMOTION:
            sentinelFailoverWaitPromotion(ri);
            break;

        case SENTINEL_FAILOVER_STATE_RECONF_SLAVES:
            sentinelFailoverReconfNextSlave(ri);
            break;
    }
}

// 阶段1：等待开始
void sentinelFailoverWaitStart(sentinelRedisInstance *ri) {
    char *leader;
    int isleader;

    // 检查是否被选为领导者
    leader = sentinelGetLeader(ri, &ri->leader_epoch);
    isleader = (leader && strcmp(leader, sentinel.myid) == 0);

    if (!isleader) {
        // 不是领导者，等待
        ri->failover_state = SENTINEL_FAILOVER_STATE_WAIT_START;
        ri->failover_start_time = mstime() + rand() % SENTINEL_MAX_DESYNC;
        return;
    }

    // 是领导者，进入下一阶段
    ri->failover_state = SENTINEL_FAILOVER_STATE_SELECT_SLAVE;
    ri->failover_epoch = sentinel.current_epoch;
    sentinelEvent(LL_WARNING, "+elected-leader", ri, "%@");
}

// 阶段2：选择从节点
void sentinelFailoverSelectSlave(sentinelRedisInstance *master) {
    sentinelRedisInstance *slave;

    slave = sentinelSelectSlave(master);
    if (slave == NULL) {
        // 没有可用的从节点
        sentinelAbortFailover(master);
        return;
    }

    master->promoted_slave = slave;
    master->failover_state = SENTINEL_FAILOVER_STATE_SEND_SLAVEOF_NOONE;
    sentinelEvent(LL_WARNING, "+selected-slave", slave, "%@");
}

// 阶段3：发送SLAVEOF NO ONE
void sentinelFailoverSendSlaveOfNoOne(sentinelRedisInstance *master) {
    int retval;

    retval = sentinelSendSlaveOf(master->promoted_slave, NULL, 0);
    if (retval == C_OK) {
        master->failover_state = SENTINEL_FAILOVER_STATE_WAIT_PROMOTION;
        master->failover_state_change_time = mstime();
    }
}

// 阶段4：等待提升
void sentinelFailoverWaitPromotion(sentinelRedisInstance *ri) {
    mstime_t elapsed = mstime() - ri->failover_state_change_time;
    sentinelRedisInstance *slave = ri->promoted_slave;

    if (elapsed > SENTINEL_PROMOTE_TIMEOUT) {
        // 超时，取消故障转移
        sentinelAbortFailover(ri);
        return;
    }

    // 检查从节点是否已提升为主节点
    if (slave->flags & SRI_PROMOTED) {
        ri->failover_state = SENTINEL_FAILOVER_STATE_RECONF_SLAVES;
        ri->failover_state_change_time = mstime();
        sentinelEvent(LL_WARNING, "+promoted-slave", slave, "%@");
    }
}

// 阶段5：重新配置从节点
void sentinelFailoverReconfNextSlave(sentinelRedisInstance *master) {
    dictIterator *di;
    dictEntry *de;
    int in_progress = 0;

    di = dictGetIterator(master->slaves);
    while((de = dictNext(di)) != NULL) {
        sentinelRedisInstance *slave = dictGetVal(de);

        if (slave->flags & SRI_RECONF_SENT) {
            in_progress++;
            continue;
        }

        if (slave->flags & (SRI_RECONF_INPROG | SRI_RECONF_DONE)) {
            continue;
        }

        // 发送SLAVEOF命令
        if (slave->flags & SRI_PROMOTED) {
            continue; // 跳过新主节点
        }

        sentinelSendSlaveOf(slave, master->promoted_slave->addr->ip,
                           master->promoted_slave->addr->port);
        slave->flags |= SRI_RECONF_SENT;
        slave->reconf_sent_time = mstime();
        in_progress++;
    }
    dictReleaseIterator(di);

    if (in_progress == 0) {
        // 所有从节点已重新配置
        master->failover_state = SENTINEL_FAILOVER_STATE_NONE;
        master->flags &= ~SRI_FAILOVER_IN_PROGRESS;
        sentinelEvent(LL_WARNING, "+failover-end", master, "%@");
    }
}
```

### 5.2 Leader选举

**Leader选举算法**：

使用Raft算法变种，需要超过50%的Sentinel投票才能成为Leader。

**选举流程**：

1. 收集所有Sentinel的投票
2. 统计每个候选者的票数
3. 选择票数超过$\lceil \frac{n}{2} \rceil$的候选者作为Leader

## 6. 性能分析

### 6.1 故障转移时间分析

**故障转移时间**：

$$T_{failover} = T_{detect} + T_{elect} + T_{promote} + T_{reconf}$$

其中：

- $T_{detect}$：故障检测时间（~5秒）
- $T_{elect}$：Leader选举时间（~1秒）
- $T_{promote}$：从节点提升时间（~1秒）
- $T_{reconf}$：重新配置从节点时间（~2秒）

**总时间**：$T_{failover} \approx 9\text{秒}$

### 6.2 可用性分析

**可用性计算**：

$$Availability = 1 - \frac{MTTR}{MTBF + MTTR}$$

其中：

- $MTTR$：平均修复时间（~9秒）
- $MTBF$：平均故障间隔时间（假设1年）

**可用性**：$Availability \approx 99.9997\%$（5个9）

## 7. 配置与使用

### 7.1 Sentinel配置文件

```conf
# sentinel.conf

# 监控主节点
sentinel monitor mymaster 127.0.0.1 6379 2

# 主观下线时间（毫秒）
sentinel down-after-milliseconds mymaster 5000

# 故障转移超时时间（毫秒）
sentinel failover-timeout mymaster 10000

# 并行同步的从节点数
sentinel parallel-syncs mymaster 1

# 密码（如果主节点有密码）
sentinel auth-pass mymaster mypassword
```

### 7.2 启动Sentinel

```bash
# 启动Sentinel
redis-sentinel sentinel.conf

# 或使用Redis服务器模式
redis-server sentinel.conf --sentinel
```

### 7.3 客户端集成

**自动发现主节点**：

```python
import redis.sentinel

# 连接Sentinel
sentinel = redis.sentinel.Sentinel([
    ('localhost', 26379),
    ('localhost', 26380),
    ('localhost', 26381)
])

# 获取主节点
master = sentinel.master_for('mymaster', socket_timeout=0.1)

# 获取从节点
slave = sentinel.slave_for('mymaster', socket_timeout=0.1)

# 使用
master.set('key', 'value')
value = slave.get('key')
```

## 8. 适用场景

### 8.1 优势场景

1. **高可用要求**：需要自动故障转移的场景
2. **主从架构**：使用主从复制架构的场景
3. **单点写入**：只需要单点写入的场景

### 8.2 不适用场景

1. **水平扩展**：需要水平扩展的场景（建议使用Cluster）
2. **多主写入**：需要多主写入的场景（建议使用Cluster）

## 9. 扩展阅读

- [主从复制机制](./03.03.01-主从复制机制.md)
- [Cluster集群模式](./03.03.03-Cluster集群模式.md)
- [高可用架构总览](../README.md)

## 10. 权威参考

### 10.1 官方文档

1. **Redis源码 - sentinel.c**
   - URL: <https://github.com/redis/redis/blob/unstable/src/sentinel.c>
   - 版本: Redis 2.6+
   - Sentinel的完整实现源码

2. **Redis官方文档 - Redis Sentinel**
   - URL: <https://redis.io/docs/manual/sentinel/>
   - 版本: Redis 7.0+
   - Sentinel的官方文档

### 10.2 经典书籍

1. **《Redis设计与实现》** - 黄健宏
   - 出版社: 机械工业出版社
   - ISBN: 978-7111464747
   - 第15章：Sentinel（详细分析Sentinel实现）

2. **《Redis深度历险：核心原理与应用实践》** - 钱文品
   - 出版社: 电子工业出版社
   - ISBN: 978-7121356128
   - 第4章：Redis高可用（Sentinel应用）

### 10.3 学术论文

1. **"In Search of an Understandable Consensus Algorithm"** - Diego Ongaro, John Ousterhout, USENIX ATC, 2014
   - Raft算法的原始论文
   - URL: <https://raft.github.io/raft.pdf>
   - Sentinel的Leader选举基于Raft算法变种

### 10.4 在线资源

1. **Wikipedia - Raft (algorithm)**
   - URL: <https://en.wikipedia.org/wiki/Raft_(algorithm)>
   - 提供Raft算法的详细说明
