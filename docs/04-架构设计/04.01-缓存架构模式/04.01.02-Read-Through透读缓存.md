# 04.01.02 Read-Through透读缓存

## 概述

Read-Through（透读缓存）是一种缓存模式，应用程序将缓存视为主要数据源，缓存负责在未命中时从数据源加载数据。这种模式将读逻辑封装在缓存层，简化了应用程序代码。

## 核心思想

### 设计原则

1. **缓存即服务**：缓存层负责数据加载逻辑
2. **透明访问**：应用程序无需关心数据来源
3. **自动加载**：缓存未命中时自动从数据源加载

### 工作流程

```
┌─────────┐         ┌─────────┐         ┌─────────┐
│  应用   │────────▶│  缓存   │         │  数据库  │
└─────────┘         └─────────┘         └─────────┘
     │                   │                   │
     │  1. 读取请求       │                   │
     │──────────────────▶│                   │
     │                   │                   │
     │  2. 缓存未命中     │                   │
     │◀──────────────────│                   │
     │                   │  3. 加载数据       │
     │                   │──────────────────▶│
     │                   │  4. 返回数据       │
     │                   │◀──────────────────│
     │                   │                   │
     │  5. 写入缓存       │                   │
     │                   │──────────────────▶│
     │                   │                   │
     │  6. 返回数据       │                   │
     │◀──────────────────│                   │
```

## 实现模式

### 基础实现

```python
class ReadThroughCache:
    def __init__(self, cache_client, db_client, loader_func):
        self.cache = cache_client
        self.db = db_client
        self.loader = loader_func  # 数据加载函数

    def get(self, key):
        # 1. 先查缓存
        value = self.cache.get(key)
        if value is not None:
            return value

        # 2. 缓存未命中，从数据源加载
        value = self.loader(key, self.db)

        if value is not None:
            # 3. 写入缓存
            self.cache.set(key, value, ttl=3600)

        return value
```

### 带锁实现（防止缓存击穿）

```python
import threading
from functools import wraps

class ReadThroughCacheWithLock:
    def __init__(self, cache_client, db_client, loader_func):
        self.cache = cache_client
        self.db = db_client
        self.loader = loader_func
        self.locks = {}  # key -> Lock
        self.lock_lock = threading.Lock()  # 保护locks字典

    def _get_lock(self, key):
        """获取或创建key对应的锁"""
        with self.lock_lock:
            if key not in self.locks:
                self.locks[key] = threading.Lock()
            return self.locks[key]

    def get(self, key):
        # 1. 先查缓存
        value = self.cache.get(key)
        if value is not None:
            return value

        # 2. 获取锁
        lock = self._get_lock(key)
        with lock:
            # 3. 双重检查（可能其他线程已经加载）
            value = self.cache.get(key)
            if value is not None:
                return value

            # 4. 从数据源加载
            value = self.loader(key, self.db)

            if value is not None:
                # 5. 写入缓存
                self.cache.set(key, value, ttl=3600)

            return value
```

### Redis实现示例

```python
import redis
import json

class RedisReadThroughCache:
    def __init__(self, redis_client, db_client):
        self.redis = redis_client
        self.db = db_client

    def get_user(self, user_id):
        cache_key = f"user:{user_id}"

        # 1. 从Redis读取
        cached = self.redis.get(cache_key)
        if cached:
            return json.loads(cached)

        # 2. 从数据库加载
        user = self.db.query("SELECT * FROM users WHERE id = ?", user_id)

        if user:
            # 3. 写入Redis
            self.redis.setex(
                cache_key,
                3600,  # 1小时TTL
                json.dumps(user)
            )

        return user
```

## 一致性保证

### 最终一致性模型

Read-Through保证**最终一致性**：

1. **读取时**：缓存未命中则从数据源加载
2. **写入时**：需要配合Write-Through或Cache-Aside
3. **时间窗口**：数据更新到缓存失效之间存在不一致窗口

### 一致性策略

#### 1. TTL过期

```python
# 设置TTL，定期刷新
cache.set(key, value, ttl=3600)  # 1小时后过期
```

#### 2. 主动失效

```python
# 数据更新时删除缓存
def update_user(user_id, user_data):
    # 更新数据库
    db.update("users", user_id, user_data)

    # 删除缓存
    cache.delete(f"user:{user_id}")
```

#### 3. 版本控制

```python
# 使用版本号保证一致性
def get_user(user_id):
    cache_key = f"user:{user_id}"
    cached = cache.get(cache_key)

    if cached:
        cached_version = cached['version']
        db_version = get_db_version(user_id)

        if cached_version == db_version:
            return cached['data']
        else:
            # 版本不一致，重新加载
            cache.delete(cache_key)

    # 从数据库加载
    user = db.query("SELECT * FROM users WHERE id = ?", user_id)
    cache.set(cache_key, {
        'data': user,
        'version': user['version']
    }, ttl=3600)

    return user
```

## 性能特征

### 优势

| 特性 | 说明 |
|------|------|
| **代码简化** | 应用程序无需处理缓存逻辑 |
| **封装性好** | 读逻辑集中在缓存层 |
| **易于维护** | 缓存策略统一管理 |
| **扩展性强** | 可以轻松添加缓存层 |

### 劣势

| 特性 | 说明 |
|------|------|
| **延迟增加** | 缓存未命中时需要额外加载时间 |
| **复杂度** | 缓存层需要实现加载逻辑 |
| **耦合度** | 缓存层需要了解数据源结构 |

## 适用场景

### 优势场景

1. **缓存即服务（CaaS）**
   - 缓存作为独立服务提供
   - 应用程序无需关心缓存细节

2. **多应用共享缓存**
   - 多个应用共享同一缓存
   - 统一管理缓存逻辑

3. **复杂加载逻辑**
   - 数据加载逻辑复杂
   - 封装在缓存层便于复用

### 不适用场景

1. **简单场景**
   - 数据加载逻辑简单
   - Cache-Aside更直接

2. **高性能要求**
   - 需要精确控制缓存行为
   - Cache-Aside更灵活

## 与其他模式对比

### Read-Through vs Cache-Aside

| **维度** | **Read-Through** | **Cache-Aside** |
|----------|------------------|----------------|
| **代码位置** | 缓存层 | 应用层 |
| **复杂度** | 缓存层复杂 | 应用层复杂 |
| **封装性** | 高 | 低 |
| **灵活性** | 低 | 高 |
| **适用场景** | CaaS、多应用共享 | 简单场景 |

### Read-Through vs Write-Through

Read-Through和Write-Through可以组合使用：

```python
class ReadWriteThroughCache:
    def get(self, key):
        # Read-Through逻辑
        value = self.cache.get(key)
        if value is None:
            value = self.loader(key)
            self.cache.set(key, value)
        return value

    def set(self, key, value):
        # Write-Through逻辑
        self.db.set(key, value)
        self.cache.set(key, value)
```

## 优化策略

### 1. 预加载

```python
# 预加载热点数据
def warmup_cache():
    hot_keys = db.query("SELECT id FROM hot_items")
    for key in hot_keys:
        value = loader(key)
        cache.set(key, value)
```

### 2. 批量加载

```python
# 批量加载减少数据库查询
def batch_get(self, keys):
    # 1. 批量从缓存读取
    cached = cache.mget(keys)

    # 2. 找出未命中的key
    missing_keys = [k for k, v in zip(keys, cached) if v is None]

    # 3. 批量从数据库加载
    if missing_keys:
        db_values = db.batch_query(missing_keys)
        # 4. 批量写入缓存
        cache.mset(dict(zip(missing_keys, db_values)))

    return cached
```

### 3. 异步加载

```python
import asyncio

async def async_get(self, key):
    # 1. 先查缓存
    value = await cache.get(key)
    if value:
        return value

    # 2. 异步加载
    value = await asyncio.to_thread(self.loader, key)

    # 3. 异步写入缓存
    if value:
        await cache.set(key, value)

    return value
```

## 扩展阅读

- [Cache-Aside旁路缓存](./04.01.01-Cache-Aside旁路缓存.md)
- [Write-Through透写缓存](./04.01.03-Write-Through透写缓存.md)
- [缓存问题与治理](../04.04-缓存问题与治理/README.md)

## 权威参考

- **《企业应用架构模式》** - Martin Fowler
- **《分布式系统概念与设计》** - 分布式系统经典教材
- **AWS架构最佳实践** - Read-Through模式
