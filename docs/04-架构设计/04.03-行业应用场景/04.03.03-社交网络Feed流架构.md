# 04.03.03 社交网络：Feed流架构

## 概述

社交网络Feed流场景需要处理**海量用户的时间线生成**，既要保证实时性，又要控制成本。本架构通过多级缓存、预计算和智能推送，实现高性能Feed流系统。

## 业务特征与极端要求

### 核心要求

- **实时性要求**：新内容1秒内推送到关注者
- **个性化要求**：每个用户看到不同的Feed流
- **规模要求**：支持亿级用户，千万级内容
- **成本要求**：控制存储和计算成本

### 业务特征

- **数据特征**：用户关系、内容、互动数据
- **访问模式**：读多写多，时间局部性强
- **核心痛点**：时间线生成、实时推送、存储成本

## 架构设计

### 架构拓扑

```text
┌─────────────┐
│  内容发布    │
└──────┬──────┘
       │
       ▼
┌─────────────┐         ┌─────────────┐
│ 内容存储     │────────▶│ 内容缓存    │
│ (MySQL)     │         │ (Redis)      │
└─────────────┘         └─────────────┘
       │                        │
       │                        │
       ▼                        ▼
┌─────────────┐         ┌─────────────┐
│ 关系存储     │────────▶│ 关系缓存    │
│ (Neo4j)     │         │ (Redis)      │
└─────────────┘         └─────────────┘
       │                        │
       │                        │
       ▼                        ▼
┌─────────────┐         ┌─────────────┐
│ 时间线生成   │────────▶│ 时间线缓存  │
│ (计算层)     │         │ (Redis)     │
└─────────────┘         └─────────────┘
       │                        │
       │                        │
       ▼                        ▼
┌─────────────┐         ┌─────────────┐
│ Feed流API   │────────▶│ 客户端      │
└─────────────┘         └─────────────┘
```

## 核心方案

### 方案1：推模式（Push Model）

```python
class PushFeedService:
    def __init__(self):
        self.redis = redis.Redis()
        self.relation_db = Neo4j()
        self.content_db = MySQL()

    def publish_content(self, user_id, content):
        # 1. 存储内容
        content_id = self.content_db.insert(content)

        # 2. 获取粉丝列表
        followers = self.relation_db.get_followers(user_id)

        # 3. 推送到每个粉丝的时间线
        for follower_id in followers:
            timeline_key = f"timeline:{follower_id}"
            # 使用Sorted Set存储时间线
            self.redis.zadd(
                timeline_key,
                {content_id: time.time()},
                maxlen=1000  # 只保留最近1000条
            )

    def get_feed(self, user_id, page=1, page_size=20):
        timeline_key = f"timeline:{user_id}"
        # 获取时间线（按时间倒序）
        content_ids = self.redis.zrevrange(
            timeline_key,
            (page - 1) * page_size,
            page * page_size - 1
        )

        # 批量获取内容
        contents = self.batch_get_content(content_ids)
        return contents
```

**优势**：

- 读取延迟低（O(logN)）
- 用户体验好

**劣势**：

- 写入成本高（粉丝数×写入操作）
- 大V发布时压力大

### 方案2：拉模式（Pull Model）

```python
class PullFeedService:
    def __init__(self):
        self.redis = redis.Redis()
        self.relation_db = Neo4j()
        self.content_db = MySQL()

    def publish_content(self, user_id, content):
        # 1. 存储内容
        content_id = self.content_db.insert(content)

        # 2. 存储到发布者的内容列表
        content_key = f"content:{user_id}"
        self.redis.zadd(
            content_key,
            {content_id: time.time()},
            maxlen=1000
        )

    def get_feed(self, user_id, page=1, page_size=20):
        # 1. 获取关注列表
        following_key = f"following:{user_id}"
        following_ids = self.redis.smembers(following_key)

        # 2. 合并所有关注者的内容
        all_content_ids = []
        for following_id in following_ids:
            content_key = f"content:{following_id}"
            content_ids = self.redis.zrevrange(content_key, 0, 100)
            all_content_ids.extend(content_ids)

        # 3. 按时间排序
        all_content_ids.sort(key=lambda x: self.get_timestamp(x), reverse=True)

        # 4. 分页返回
        start = (page - 1) * page_size
        end = start + page_size
        return self.batch_get_content(all_content_ids[start:end])
```

**优势**：

- 写入成本低
- 存储成本低

**劣势**：

- 读取延迟高（需要合并多个时间线）
- 关注数多时性能差

### 方案3：混合模式（Hybrid Model）

```python
class HybridFeedService:
    def __init__(self, push_threshold=1000):
        self.redis = redis.Redis()
        self.relation_db = Neo4j()
        self.content_db = MySQL()
        self.push_threshold = push_threshold  # 粉丝数阈值

    def publish_content(self, user_id, content):
        # 1. 存储内容
        content_id = self.content_db.insert(content)

        # 2. 获取粉丝数
        follower_count = self.relation_db.get_follower_count(user_id)

        if follower_count <= self.push_threshold:
            # 小V：推模式
            self.push_to_followers(user_id, content_id)
        else:
            # 大V：拉模式
            self.store_content(user_id, content_id)

    def push_to_followers(self, user_id, content_id):
        """推送到粉丝时间线"""
        followers = self.relation_db.get_followers(user_id)
        for follower_id in followers:
            timeline_key = f"timeline:{follower_id}"
            self.redis.zadd(timeline_key, {content_id: time.time()})

    def get_feed(self, user_id, page=1, page_size=20):
        # 1. 获取推模式的时间线
        timeline_key = f"timeline:{user_id}"
        pushed_content_ids = self.redis.zrevrange(
            timeline_key,
            (page - 1) * page_size,
            page * page_size - 1
        )

        # 2. 如果不够，补充拉模式的内容
        if len(pushed_content_ids) < page_size:
            pulled_content_ids = self.pull_from_following(user_id)
            all_content_ids = list(set(pushed_content_ids + pulled_content_ids))
            all_content_ids.sort(key=lambda x: self.get_timestamp(x), reverse=True)
            pushed_content_ids = all_content_ids[:page_size]

        return self.batch_get_content(pushed_content_ids)
```

**优势**：

- 平衡读写性能
- 控制成本

**劣势**：

- 实现复杂
- 需要维护两套逻辑

## 优化策略

### 1. 预计算时间线

```python
class PrecomputedFeedService:
    def __init__(self):
        self.redis = redis.Redis()
        self.background_worker = BackgroundWorker()

    def background_precompute(self):
        """后台预计算时间线"""
        while True:
            # 获取活跃用户
            active_users = self.get_active_users()

            for user_id in active_users:
                # 预计算时间线
                self.precompute_timeline(user_id)

            time.sleep(60)  # 每分钟更新一次

    def precompute_timeline(self, user_id):
        """预计算用户时间线"""
        # 1. 获取关注列表
        following_ids = self.get_following(user_id)

        # 2. 合并所有关注者的内容
        all_content_ids = []
        for following_id in following_ids:
            content_ids = self.get_recent_content(following_id, limit=100)
            all_content_ids.extend(content_ids)

        # 3. 按时间排序
        all_content_ids.sort(key=lambda x: self.get_timestamp(x), reverse=True)

        # 4. 存储预计算的时间线
        timeline_key = f"precomputed:timeline:{user_id}"
        self.redis.delete(timeline_key)
        for content_id in all_content_ids[:1000]:
            self.redis.zadd(timeline_key, {content_id: self.get_timestamp(content_id)})
```

### 2. 智能推送

```python
class SmartPushService:
    def __init__(self):
        self.redis = redis.Redis()
        self.ml_model = load_ml_model()  # 机器学习模型

    def should_push(self, user_id, follower_id, content):
        """判断是否应该推送"""
        # 1. 检查用户活跃度
        if not self.is_active_user(follower_id):
            return False

        # 2. 检查内容相关性
        relevance_score = self.ml_model.predict(user_id, follower_id, content)
        if relevance_score < 0.5:
            return False

        # 3. 检查推送频率
        push_count = self.redis.get(f"push_count:{follower_id}")
        if push_count and int(push_count) > 100:  # 每天最多100条
            return False

        return True

    def publish_content(self, user_id, content):
        content_id = self.content_db.insert(content)

        followers = self.relation_db.get_followers(user_id)
        for follower_id in followers:
            if self.should_push(user_id, follower_id, content):
                timeline_key = f"timeline:{follower_id}"
                self.redis.zadd(timeline_key, {content_id: time.time()})
                # 更新推送计数
                self.redis.incr(f"push_count:{follower_id}")
```

### 3. 多级缓存

```python
class MultiLevelFeedCache:
    def __init__(self):
        self.l1_cache = {}  # 本地缓存（最近访问的用户）
        self.l2_cache = redis.Redis(host='localhost')  # 本地Redis
        self.l3_cache = redis.Redis(host='remote')  # 远程Redis

    def get_feed(self, user_id, page=1, page_size=20):
        cache_key = f"feed:{user_id}:{page}"

        # L1: 本地缓存
        if cache_key in self.l1_cache:
            return self.l1_cache[cache_key]

        # L2: 本地Redis
        cached = self.l2_cache.get(cache_key)
        if cached:
            feed = json.loads(cached)
            self.l1_cache[cache_key] = feed
            return feed

        # L3: 远程Redis
        cached = self.l3_cache.get(cache_key)
        if cached:
            feed = json.loads(cached)
            self.l2_cache.setex(cache_key, 60, json.dumps(feed))
            self.l1_cache[cache_key] = feed
            return feed

        # 计算Feed流
        feed = self.compute_feed(user_id, page, page_size)

        # 写入缓存
        self.l3_cache.setex(cache_key, 300, json.dumps(feed))
        self.l2_cache.setex(cache_key, 60, json.dumps(feed))
        self.l1_cache[cache_key] = feed

        return feed
```

## 性能优化

### 1. 批量操作

```python
# 批量获取内容
def batch_get_content(self, content_ids):
    # 使用Pipeline批量查询
    pipe = self.redis.pipeline()
    for content_id in content_ids:
        pipe.get(f"content:{content_id}")
    results = pipe.execute()

    # 过滤None值
    contents = [json.loads(r) for r in results if r]
    return contents
```

### 2. 异步处理

```python
import asyncio

class AsyncFeedService:
    async def publish_content(self, user_id, content):
        # 1. 异步存储内容
        content_id = await asyncio.to_thread(
            self.content_db.insert, content
        )

        # 2. 异步推送到粉丝
        followers = await asyncio.to_thread(
            self.relation_db.get_followers, user_id
        )

        # 3. 并发推送
        tasks = [
            self.push_to_follower(follower_id, content_id)
            for follower_id in followers
        ]
        await asyncio.gather(*tasks)
```

## 扩展阅读

- [电商秒杀架构](./04.03.01-电商零售秒杀架构.md)
- [金融支付架构](./04.03.02-金融科技支付架构.md)
- [热点Key问题](../04.04-缓存问题与治理/04.04.04-热点Key问题.md)

## 权威参考

- **《大型网站技术架构》** - 李智慧著
- **《高并发系统设计》** - 大型互联网公司技术博客
- **Twitter Engineering Blog** - Feed流架构设计
