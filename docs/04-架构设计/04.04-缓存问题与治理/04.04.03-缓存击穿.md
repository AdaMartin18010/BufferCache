# 04.04.03 缓存击穿

## 概述

缓存击穿是指**热点key过期**，此时大量并发请求同时访问该key，由于缓存未命中，所有请求都穿透到数据库，造成数据库压力激增。

## 问题场景

### 典型场景

```
热点key过期 → 100万并发请求 → 100万次数据库查询 → 数据库崩溃
```

### 与缓存穿透的区别

| **维度** | **缓存穿透** | **缓存击穿** |
|----------|--------------|--------------|
| **数据存在性** | 数据不存在 | 数据存在但过期 |
| **请求特征** | 查询不存在的数据 | 查询热点数据 |
| **影响范围** | 多个不同的key | 单个热点key |
| **解决方案** | 布隆过滤器+空值缓存 | 互斥锁+异步重建 |

## 问题原因

### 根本原因

1. **热点key过期**：热门数据缓存过期
2. **高并发访问**：大量用户同时访问
3. **缓存未命中**：缓存中没有数据

### 示例代码

```python
# 问题代码
def get_hot_product(product_id):
    cache_key = f"product:{product_id}"

    # 1. 查询缓存
    cached = cache.get(cache_key)
    if cached:
        return json.loads(cached)

    # 2. 问题：100万并发请求同时到达这里
    # 3. 100万次数据库查询
    product = db.query("SELECT * FROM products WHERE id = ?", product_id)

    # 4. 写入缓存
    cache.setex(cache_key, 3600, json.dumps(product))

    return product
```

## 解决方案

### 方案1：互斥锁

```python
import threading
from functools import wraps

class CacheWithMutex:
    def __init__(self):
        self.cache = redis.Redis()
        self.db = MySQL()
        self.locks = {}
        self.lock_lock = threading.Lock()

    def get_lock(self, key):
        with self.lock_lock:
            if key not in self.locks:
                self.locks[key] = threading.Lock()
            return self.locks[key]

    def get_hot_product(self, product_id):
        cache_key = f"product:{product_id}"

        # 1. 查询缓存
        cached = self.cache.get(cache_key)
        if cached:
            return json.loads(cached)

        # 2. 获取互斥锁
        lock = self.get_lock(cache_key)
        with lock:
            # 3. 双重检查（可能其他线程已经重建）
            cached = self.cache.get(cache_key)
            if cached:
                return json.loads(cached)

            # 4. 查询数据库（只有一个线程执行）
            product = self.db.query("SELECT * FROM products WHERE id = ?", product_id)

            if product:
                # 5. 写入缓存
                ttl = 3600 + random.randint(-300, 300)
                self.cache.setex(cache_key, ttl, json.dumps(product))

            return product
```

**效果**：
- 原始：100万次数据库查询
- 优化后：1次数据库查询 + 999,999次缓存重试
- **数据库压力降低6个数量级**

### 方案2：分布式锁（Redis）

```python
import redis
import time
import uuid

class CacheWithDistributedLock:
    def __init__(self):
        self.cache = redis.Redis()
        self.db = MySQL()
        self.lock_timeout = 10  # 锁超时时间

    def acquire_lock(self, key, timeout=10):
        lock_key = f"lock:{key}"
        lock_value = str(uuid.uuid4())
        end_time = time.time() + timeout

        while time.time() < end_time:
            # 尝试获取锁
            if self.cache.set(lock_key, lock_value, nx=True, ex=self.lock_timeout):
                return lock_value
            time.sleep(0.001)  # 等待1ms

        return None

    def release_lock(self, key, lock_value):
        lock_key = f"lock:{key}"
        # Lua脚本保证原子性
        script = """
        if redis.call('get', KEYS[1]) == ARGV[1] then
            return redis.call('del', KEYS[1])
        else
            return 0
        end
        """
        self.cache.eval(script, 1, lock_key, lock_value)

    def get_hot_product(self, product_id):
        cache_key = f"product:{product_id}"

        # 1. 查询缓存
        cached = self.cache.get(cache_key)
        if cached:
            return json.loads(cached)

        # 2. 获取分布式锁
        lock_value = self.acquire_lock(cache_key)
        if not lock_value:
            # 获取锁失败，等待后重试
            time.sleep(0.05)  # 等待50ms
            return self.get_hot_product(product_id)  # 重试

        try:
            # 3. 双重检查
            cached = self.cache.get(cache_key)
            if cached:
                return json.loads(cached)

            # 4. 查询数据库
            product = self.db.query("SELECT * FROM products WHERE id = ?", product_id)

            if product:
                # 5. 写入缓存
                ttl = 3600 + random.randint(-300, 300)
                self.cache.setex(cache_key, ttl, json.dumps(product))

            return product
        finally:
            # 6. 释放锁
            self.release_lock(cache_key, lock_value)
```

### 方案3：异步重建

```python
import asyncio
from queue import Queue
import threading

class CacheWithAsyncRebuild:
    def __init__(self):
        self.cache = redis.Redis()
        self.db = MySQL()
        self.rebuild_queue = Queue()
        self.rebuilding = set()
        self.start_rebuild_worker()

    def start_rebuild_worker(self):
        def worker():
            while True:
                try:
                    key, loader_func = self.rebuild_queue.get(timeout=1)
                    # 异步重建缓存
                    value = loader_func()
                    if value:
                        ttl = 3600 + random.randint(-300, 300)
                        self.cache.setex(key, ttl, json.dumps(value))
                    self.rebuilding.discard(key)
                except Exception as e:
                    logger.error(f"Rebuild failed: {e}")
                finally:
                    self.rebuild_queue.task_done()

        threading.Thread(target=worker, daemon=True).start()

    def get_hot_product(self, product_id):
        cache_key = f"product:{product_id}"

        # 1. 查询缓存
        cached = self.cache.get(cache_key)
        if cached:
            return json.loads(cached)

        # 2. 检查是否正在重建
        if cache_key in self.rebuilding:
            # 等待重建完成
            time.sleep(0.1)
            cached = self.cache.get(cache_key)
            if cached:
                return json.loads(cached)

        # 3. 标记为重建中
        self.rebuilding.add(cache_key)

        # 4. 加入重建队列
        self.rebuild_queue.put((cache_key, lambda: self.load_product(product_id)))

        # 5. 返回默认值或降级数据
        return self.get_default_product(product_id)

    def load_product(self, product_id):
        return self.db.query("SELECT * FROM products WHERE id = ?", product_id)

    def get_default_product(self, product_id):
        # 返回降级数据
        return {"id": product_id, "name": "加载中...", "price": 0}
```

### 方案4：热点数据永不过期

```python
class CacheWithHotKey:
    def __init__(self):
        self.cache = redis.Redis()
        self.db = MySQL()
        self.hot_keys = set()  # 热点key集合

    def mark_hot_key(self, key):
        """标记为热点key"""
        self.hot_keys.add(key)

    def get_hot_product(self, product_id):
        cache_key = f"product:{product_id}"

        # 1. 查询缓存
        cached = self.cache.get(cache_key)
        if cached:
            # 热点key：延长过期时间
            if cache_key in self.hot_keys:
                self.cache.expire(cache_key, 3600)
            return json.loads(cached)

        # 2. 查询数据库
        product = self.db.query("SELECT * FROM products WHERE id = ?", product_id)

        if product:
            # 热点key：永不过期（通过后台任务更新）
            if cache_key in self.hot_keys:
                self.cache.set(cache_key, json.dumps(product))  # 不过期
            else:
                ttl = 3600 + random.randint(-300, 300)
                self.cache.setex(cache_key, ttl, json.dumps(product))

        return product

    def background_refresh_hot_keys(self):
        """后台任务刷新热点key"""
        while True:
            for key in self.hot_keys:
                # 重新加载数据
                product_id = key.split(':')[1]
                product = self.db.query("SELECT * FROM products WHERE id = ?", product_id)
                if product:
                    self.cache.set(key, json.dumps(product))
            time.sleep(300)  # 每5分钟刷新一次
```

## 性能对比

| 方案 | 数据库查询次数 | 延迟 | 实现复杂度 | 适用场景 |
|------|----------------|------|------------|----------|
| **互斥锁** | 1次 | 低 | 低 | 单机场景 |
| **分布式锁** | 1次 | 中 | 中 | 分布式场景 |
| **异步重建** | 1次 | 低 | 高 | 高并发场景 |
| **永不过期** | 0次（后台更新） | 最低 | 中 | 热点数据 |

## 最佳实践

### 组合方案

```python
class CacheBreakthroughPrevention:
    def __init__(self):
        self.cache = redis.Redis()
        self.db = MySQL()
        self.hot_keys = set()
        self.locks = {}
        self.lock_lock = threading.Lock()

    def get_hot_product(self, product_id):
        cache_key = f"product:{product_id}"

        # 1. 查询缓存
        cached = self.cache.get(cache_key)
        if cached:
            # 热点key：延长过期时间
            if cache_key in self.hot_keys:
                self.cache.expire(cache_key, 3600)
            return json.loads(cached)

        # 2. 热点key：永不过期策略
        if cache_key in self.hot_keys:
            product = self.db.query("SELECT * FROM products WHERE id = ?", product_id)
            if product:
                self.cache.set(cache_key, json.dumps(product))  # 不过期
            return product

        # 3. 普通key：互斥锁策略
        lock = self.get_lock(cache_key)
        with lock:
            # 双重检查
            cached = self.cache.get(cache_key)
            if cached:
                return json.loads(cached)

            product = self.db.query("SELECT * FROM products WHERE id = ?", product_id)
            if product:
                ttl = 3600 + random.randint(-300, 300)
                self.cache.setex(cache_key, ttl, json.dumps(product))

            return product
```

## 监控与告警

### 关键指标

```python
# 监控指标
metrics = {
    'hot_key_count': len(hot_keys),           # 热点key数量
    'cache_rebuild_count': rebuild_count,     # 缓存重建次数
    'lock_wait_time': lock_wait_time,         # 锁等待时间
    'db_qps': get_db_qps()                    # 数据库QPS
}

# 告警规则
if metrics['db_qps'] > 5000:  # 数据库QPS>5000
    send_alert('HIGH_DB_QPS')

if metrics['lock_wait_time'] > 100:  # 锁等待>100ms
    send_alert('HIGH_LOCK_WAIT_TIME')
```

## 扩展阅读

- [缓存穿透](./04.04.01-缓存穿透.md)
- [缓存雪崩](./04.04.02-缓存雪崩.md)
- [热点Key问题](./04.04.04-热点Key问题.md)

## 权威参考

- **《大型网站技术架构》** - 李智慧著
- **《高并发系统设计》** - 大型互联网公司技术博客
- **Redis官方文档** - <https://redis.io/docs/manual/patterns/>
