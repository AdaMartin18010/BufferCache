# 04.04.03 缓存击穿

## 目录

- [04.04.03 缓存击穿](#040403-缓存击穿)
  - [目录](#目录)
  - [1. 概述](#1-概述)
    - [1.1 定义与历史背景](#11-定义与历史背景)
    - [1.2 问题影响](#12-问题影响)
  - [2. 问题场景](#2-问题场景)
    - [2.1 典型场景](#21-典型场景)
    - [2.2 与缓存穿透的区别](#22-与缓存穿透的区别)
  - [3. 问题原因](#3-问题原因)
    - [3.1 根本原因](#31-根本原因)
    - [3.2 示例代码](#32-示例代码)
  - [4. 解决方案](#4-解决方案)
    - [4.1 方案1：互斥锁](#41-方案1互斥锁)
    - [4.2 方案2：分布式锁（Redis）](#42-方案2分布式锁redis)
    - [4.3 方案3：异步重建](#43-方案3异步重建)
    - [4.4 方案4：热点数据永不过期](#44-方案4热点数据永不过期)
  - [5. 性能分析](#5-性能分析)
    - [5.1 方案对比](#51-方案对比)
    - [5.2 性能影响](#52-性能影响)
  - [6. 最佳实践](#6-最佳实践)
    - [6.1 组合方案](#61-组合方案)
    - [6.2 监控与告警](#62-监控与告警)
      - [6.2.1 关键指标](#621-关键指标)
  - [7. 程序设计分析](#7-程序设计分析)
    - [7.1 设计模式应用](#71-设计模式应用)
    - [7.2 代码结构分析](#72-代码结构分析)
    - [7.3 设计权衡](#73-设计权衡)
    - [7.4 可扩展性分析](#74-可扩展性分析)
  - [8. 扩展阅读](#8-扩展阅读)
  - [9. 权威参考](#9-权威参考)
    - [8.1 经典书籍](#81-经典书籍)
    - [8.2 在线资源](#82-在线资源)

---

## 1. 概述

### 1.1 定义与历史背景

**缓存击穿**是指**热点key过期**，此时大量并发请求同时访问该key，由于缓存未命中，所有请求都穿透到数据库，造成数据库压力激增。

**历史发展**：

- **2000年代**：缓存击穿问题在大型网站中出现
- **2010年代**：互斥锁成为解决缓存击穿的标准方案
- **2020年代**：缓存击穿成为缓存架构设计的核心问题

### 1.2 问题影响

缓存击穿的影响：

1. **数据库压力激增**：大量并发请求同时穿透到数据库
2. **服务不可用**：数据库连接池耗尽
3. **性能下降**：响应时间急剧增加
4. **资源浪费**：重复查询浪费资源

## 2. 问题场景

### 2.1 典型场景

```
热点key过期 → 100万并发请求 → 100万次数据库查询 → 数据库崩溃
```

### 2.2 与缓存穿透的区别

| **维度** | **缓存穿透** | **缓存击穿** |
|----------|--------------|--------------|
| **数据存在性** | 数据不存在 | 数据存在但过期 |
| **请求特征** | 查询不存在的数据 | 查询热点数据 |
| **影响范围** | 多个不同的key | 单个热点key |
| **解决方案** | 布隆过滤器+空值缓存 | 互斥锁+异步重建 |

## 3. 问题原因

### 3.1 根本原因

1. **热点key过期**：热门数据缓存过期
2. **高并发访问**：大量用户同时访问
3. **缓存未命中**：缓存中没有数据

### 3.2 示例代码

```python
# 问题代码
def get_hot_product(product_id):
    cache_key = f"product:{product_id}"

    # 1. 查询缓存
    cached = cache.get(cache_key)
    if cached:
        return json.loads(cached)

    # 2. 问题：100万并发请求同时到达这里
    # 3. 100万次数据库查询
    product = db.query("SELECT * FROM products WHERE id = ?", product_id)

    # 4. 写入缓存
    cache.setex(cache_key, 3600, json.dumps(product))

    return product
```

## 4. 解决方案

### 4.1 方案1：互斥锁

```python
import threading
from functools import wraps

class CacheWithMutex:
    def __init__(self):
        self.cache = redis.Redis()
        self.db = MySQL()
        self.locks = {}
        self.lock_lock = threading.Lock()

    def get_lock(self, key):
        with self.lock_lock:
            if key not in self.locks:
                self.locks[key] = threading.Lock()
            return self.locks[key]

    def get_hot_product(self, product_id):
        cache_key = f"product:{product_id}"

        # 1. 查询缓存
        cached = self.cache.get(cache_key)
        if cached:
            return json.loads(cached)

        # 2. 获取互斥锁
        lock = self.get_lock(cache_key)
        with lock:
            # 3. 双重检查（可能其他线程已经重建）
            cached = self.cache.get(cache_key)
            if cached:
                return json.loads(cached)

            # 4. 查询数据库（只有一个线程执行）
            product = self.db.query("SELECT * FROM products WHERE id = ?", product_id)

            if product:
                # 5. 写入缓存
                ttl = 3600 + random.randint(-300, 300)
                self.cache.setex(cache_key, ttl, json.dumps(product))

            return product
```

**效果**：

- 原始：100万次数据库查询
- 优化后：1次数据库查询 + 999,999次缓存重试
- **数据库压力降低6个数量级**

**定理 4.1**：互斥锁可以将数据库查询次数从$N$（并发请求数）降低到$1$。

**证明**：

- 无锁：$N$个并发请求，$N$次数据库查询
- 有锁：$N$个并发请求，只有1个请求查询数据库，其他请求等待
- 数据库查询次数：$1$（降低$N$倍）

### 4.2 方案2：分布式锁（Redis）

```python
import redis
import time
import uuid

class CacheWithDistributedLock:
    def __init__(self):
        self.cache = redis.Redis()
        self.db = MySQL()
        self.lock_timeout = 10  # 锁超时时间

    def acquire_lock(self, key, timeout=10):
        lock_key = f"lock:{key}"
        lock_value = str(uuid.uuid4())
        end_time = time.time() + timeout

        while time.time() < end_time:
            # 尝试获取锁
            if self.cache.set(lock_key, lock_value, nx=True, ex=self.lock_timeout):
                return lock_value
            time.sleep(0.001)  # 等待1ms

        return None

    def release_lock(self, key, lock_value):
        lock_key = f"lock:{key}"
        # Lua脚本保证原子性
        script = """
        if redis.call('get', KEYS[1]) == ARGV[1] then
            return redis.call('del', KEYS[1])
        else
            return 0
        end
        """
        self.cache.eval(script, 1, lock_key, lock_value)

    def get_hot_product(self, product_id):
        cache_key = f"product:{product_id}"

        # 1. 查询缓存
        cached = self.cache.get(cache_key)
        if cached:
            return json.loads(cached)

        # 2. 获取分布式锁
        lock_value = self.acquire_lock(cache_key)
        if not lock_value:
            # 获取锁失败，等待后重试
            time.sleep(0.05)  # 等待50ms
            return self.get_hot_product(product_id)  # 重试

        try:
            # 3. 双重检查
            cached = self.cache.get(cache_key)
            if cached:
                return json.loads(cached)

            # 4. 查询数据库
            product = self.db.query("SELECT * FROM products WHERE id = ?", product_id)

            if product:
                # 5. 写入缓存
                ttl = 3600 + random.randint(-300, 300)
                self.cache.setex(cache_key, ttl, json.dumps(product))

            return product
        finally:
            # 6. 释放锁
            self.release_lock(cache_key, lock_value)
```

**分布式锁**：使用Redis分布式锁防止并发重建缓存。

### 4.3 方案3：异步重建

```python
import asyncio
from queue import Queue
import threading

class CacheWithAsyncRebuild:
    def __init__(self):
        self.cache = redis.Redis()
        self.db = MySQL()
        self.rebuild_queue = Queue()
        self.rebuilding = set()
        self.start_rebuild_worker()

    def start_rebuild_worker(self):
        def worker():
            while True:
                try:
                    key, loader_func = self.rebuild_queue.get(timeout=1)
                    # 异步重建缓存
                    value = loader_func()
                    if value:
                        ttl = 3600 + random.randint(-300, 300)
                        self.cache.setex(key, ttl, json.dumps(value))
                    self.rebuilding.discard(key)
                except Exception as e:
                    logger.error(f"Rebuild failed: {e}")
                finally:
                    self.rebuild_queue.task_done()

        threading.Thread(target=worker, daemon=True).start()

    def get_hot_product(self, product_id):
        cache_key = f"product:{product_id}"

        # 1. 查询缓存
        cached = self.cache.get(cache_key)
        if cached:
            return json.loads(cached)

        # 2. 检查是否正在重建
        if cache_key in self.rebuilding:
            # 等待重建完成
            time.sleep(0.1)
            cached = self.cache.get(cache_key)
            if cached:
                return json.loads(cached)

        # 3. 标记为重建中
        self.rebuilding.add(cache_key)

        # 4. 加入重建队列
        self.rebuild_queue.put((cache_key, lambda: self.load_product(product_id)))

        # 5. 返回默认值或降级数据
        return self.get_default_product(product_id)

    def load_product(self, product_id):
        return self.db.query("SELECT * FROM products WHERE id = ?", product_id)

    def get_default_product(self, product_id):
        # 返回降级数据
        return {"id": product_id, "name": "加载中...", "price": 0}
```

**异步重建**：使用异步队列重建缓存，避免阻塞请求。

### 4.4 方案4：热点数据永不过期

```python
class CacheWithHotKey:
    def __init__(self):
        self.cache = redis.Redis()
        self.db = MySQL()
        self.hot_keys = set()  # 热点key集合

    def mark_hot_key(self, key):
        """标记为热点key"""
        self.hot_keys.add(key)

    def get_hot_product(self, product_id):
        cache_key = f"product:{product_id}"

        # 1. 查询缓存
        cached = self.cache.get(cache_key)
        if cached:
            # 热点key：延长过期时间
            if cache_key in self.hot_keys:
                self.cache.expire(cache_key, 3600)
            return json.loads(cached)

        # 2. 查询数据库
        product = self.db.query("SELECT * FROM products WHERE id = ?", product_id)

        if product:
            # 热点key：永不过期（通过后台任务更新）
            if cache_key in self.hot_keys:
                self.cache.set(cache_key, json.dumps(product))  # 不过期
            else:
                ttl = 3600 + random.randint(-300, 300)
                self.cache.setex(cache_key, ttl, json.dumps(product))

        return product

    def background_refresh_hot_keys(self):
        """后台任务刷新热点key"""
        while True:
            for key in self.hot_keys:
                # 重新加载数据
                product_id = key.split(':')[1]
                product = self.db.query("SELECT * FROM products WHERE id = ?", product_id)
                if product:
                    self.cache.set(key, json.dumps(product))
            time.sleep(300)  # 每5分钟刷新一次
```

**热点数据永不过期**：热点数据永不过期，通过后台任务更新。

**定理 4.2**：热点数据永不过期可以将数据库查询次数降低到$0$（在后台更新周期内）。

**证明**：

- 热点数据永不过期：缓存中始终有数据
- 数据库查询次数：$0$（在后台更新周期内）
- 因此：数据库查询次数降低到$0$

## 5. 性能分析

### 5.1 方案对比

| 方案 | 数据库查询次数 | 延迟 | 实现复杂度 | 适用场景 |
|------|----------------|------|------------|----------|
| **互斥锁** | 1次 | 低 | 低 | 单机场景 |
| **分布式锁** | 1次 | 中 | 中 | 分布式场景 |
| **异步重建** | 1次 | 低 | 高 | 高并发场景 |
| **永不过期** | 0次（后台更新） | 最低 | 中 | 热点数据 |

### 5.2 性能影响

**性能影响**：

- **缓存击穿前**：数据库QPS = 请求QPS（正常）
- **缓存击穿后**：数据库QPS = 请求QPS（峰值）
- **使用互斥锁**：数据库QPS = 1（降低$N$倍）

## 6. 最佳实践

### 6.1 组合方案

```python
class CacheBreakthroughPrevention:
    def __init__(self):
        self.cache = redis.Redis()
        self.db = MySQL()
        self.hot_keys = set()
        self.locks = {}
        self.lock_lock = threading.Lock()

    def get_hot_product(self, product_id):
        cache_key = f"product:{product_id}"

        # 1. 查询缓存
        cached = self.cache.get(cache_key)
        if cached:
            # 热点key：延长过期时间
            if cache_key in self.hot_keys:
                self.cache.expire(cache_key, 3600)
            return json.loads(cached)

        # 2. 热点key：永不过期策略
        if cache_key in self.hot_keys:
            product = self.db.query("SELECT * FROM products WHERE id = ?", product_id)
            if product:
                self.cache.set(cache_key, json.dumps(product))  # 不过期
            return product

        # 3. 普通key：互斥锁策略
        lock = self.get_lock(cache_key)
        with lock:
            # 双重检查
            cached = self.cache.get(cache_key)
            if cached:
                return json.loads(cached)

            product = self.db.query("SELECT * FROM products WHERE id = ?", product_id)
            if product:
                ttl = 3600 + random.randint(-300, 300)
                self.cache.setex(cache_key, ttl, json.dumps(product))

            return product
```

**组合方案**：根据key类型选择不同策略。

### 6.2 监控与告警

#### 6.2.1 关键指标

```python
# 监控指标
metrics = {
    'hot_key_count': len(hot_keys),           # 热点key数量
    'cache_rebuild_count': rebuild_count,     # 缓存重建次数
    'lock_wait_time': lock_wait_time,         # 锁等待时间
    'db_qps': get_db_qps()                    # 数据库QPS
}

# 告警规则
if metrics['db_qps'] > 5000:  # 数据库QPS>5000
    send_alert('HIGH_DB_QPS')

if metrics['lock_wait_time'] > 100:  # 锁等待>100ms
    send_alert('HIGH_LOCK_WAIT_TIME')
```

**监控指标**：

- **热点key数量**：监控热点key数量
- **缓存重建次数**：监控缓存重建次数
- **锁等待时间**：监控锁等待时间
- **数据库QPS**：监控数据库QPS

## 7. 程序设计分析

### 7.1 设计模式应用

**使用的设计模式**：

1. **策略模式**：不同缓存击穿处理策略（互斥锁、分布式锁、异步重建）
2. **锁模式**：互斥锁和分布式锁实现
3. **模板方法模式**：定义缓存击穿处理的基本流程

**策略模式实现**：

```python
# 缓存击穿处理策略接口
class CacheBreakdownStrategy:
    def handle(self, key):
        raise NotImplementedError

class MutexLockStrategy(CacheBreakdownStrategy):
    def handle(self, key):
        # 互斥锁处理
        pass

class DistributedLockStrategy(CacheBreakdownStrategy):
    def handle(self, key):
        # 分布式锁处理
        pass
```

### 7.2 代码结构分析

**代码组织**：

1. **锁层**：互斥锁和分布式锁实现
2. **重建层**：异步重建实现
3. **策略层**：不同处理策略实现

**模块化设计**：

- **高内聚**：缓存击穿相关功能集中在同一模块
- **低耦合**：通过接口交互，减少依赖
- **可扩展**：易于添加新的处理策略

### 7.3 设计权衡

**设计权衡分析**：

| 权衡维度 | 选择 | 原因 |
|---------|------|------|
| **性能 vs 一致性** | 互斥锁优先 | 平衡性能和一致性 |
| **简单 vs 复杂** | 组合方案 | 支持多种场景 |
| **通用 vs 专用** | 通用缓存击穿处理 | 适用多种场景 |

**权衡公式**：

$$C_{total} = C_{performance} + C_{consistency} + C_{complexity}$$

其中：

- $C_{performance}$：性能成本（互斥锁，性能影响）
- $C_{consistency}$：一致性成本（强一致性保证）
- $C_{complexity}$：复杂度成本（组合方案，复杂度较高）

### 7.4 可扩展性分析

**扩展点**：

1. **新处理策略**：可扩展为其他处理策略
2. **新锁实现**：可扩展为其他锁实现
3. **分布式缓存击穿**：可扩展为分布式缓存击穿处理实现

**扩展性设计**：

```python
# 可扩展的缓存击穿处理接口
class CacheBreakdownManager:
    def __init__(self, strategies: List[CacheBreakdownStrategy]):
        self.strategies = strategies

    def handle(self, key):
        for strategy in self.strategies:
            strategy.handle(key)
```

**可维护性**：

- **代码清晰**：缓存击穿处理逻辑清晰，易于理解
- **易于调试**：锁状态易于监控和调试
- **测试友好**：缓存击穿处理行为易于测试和验证

## 8. 扩展阅读

- [缓存穿透](./04.04.01-缓存穿透.md)
- [缓存雪崩](./04.04.02-缓存雪崩.md)
- [热点Key问题](./04.04.04-热点Key问题.md)

## 9. 权威参考

### 9.1 经典书籍

1. **《大型网站技术架构：核心原理与案例分析》** - 李智慧
   - 出版社: 电子工业出版社
   - ISBN: 978-7121207451
   - 第4章：缓存架构（缓存击穿详解）

2. **《高并发系统设计40问》** - 沈剑
   - 出版社: 电子工业出版社
   - ISBN: 978-7121407010
   - 第10章：缓存问题（缓存击穿详解）

### 9.2 在线资源

1. **Redis官方文档 - Patterns**
   - URL: <https://redis.io/docs/manual/patterns/>
   - Redis缓存模式的官方文档

2. **Wikipedia - Cache Stampede**
   - URL: <https://en.wikipedia.org/wiki/Cache_stampede>
   - 提供缓存击穿的详细说明
