# 07.06.04 可观测性最佳实践

## 目录

- [07.06.04 可观测性最佳实践](#070604-可观测性最佳实践)
  - [目录](#目录)
  - [1. 概述](#1-概述)
    - [1.1 定义与背景](#11-定义与背景)
    - [1.2 应用价值](#12-应用价值)
  - [2. 可观测性三大支柱](#2-可观测性三大支柱)
    - [2.1 Metrics指标](#21-metrics指标)
    - [2.2 Logs日志](#22-logs日志)
    - [2.3 Traces追踪](#23-traces追踪)
  - [3. 指标设计最佳实践](#3-指标设计最佳实践)
    - [3.1 指标分类](#31-指标分类)
    - [3.2 指标命名规范](#32-指标命名规范)
    - [3.3 指标聚合策略](#33-指标聚合策略)
  - [4. 日志设计最佳实践](#4-日志设计最佳实践)
    - [4.1 结构化日志](#41-结构化日志)
    - [4.2 日志级别使用](#42-日志级别使用)
    - [4.3 日志采样策略](#43-日志采样策略)
  - [5. 追踪设计最佳实践](#5-追踪设计最佳实践)
    - [5.1 Span设计](#51-span设计)
    - [5.2 标签设计](#52-标签设计)
    - [5.3 采样策略](#53-采样策略)
  - [6. 可观测性架构](#6-可观测性架构)
    - [6.1 数据采集层](#61-数据采集层)
    - [6.2 数据存储层](#62-数据存储层)
    - [6.3 数据展示层](#63-数据展示层)
  - [7. 成本优化](#7-成本优化)
    - [7.1 数据保留策略](#71-数据保留策略)
    - [7.2 采样优化](#72-采样优化)
    - [7.3 存储优化](#73-存储优化)
  - [8. 最佳实践总结](#8-最佳实践总结)
    - [8.1 指标最佳实践](#81-指标最佳实践)
    - [8.2 日志最佳实践](#82-日志最佳实践)
    - [8.3 追踪最佳实践](#83-追踪最佳实践)
    - [8.4 成本优化最佳实践](#84-成本优化最佳实践)
  - [9. 扩展阅读](#9-扩展阅读)
  - [10. 权威参考](#10-权威参考)
    - [10.1 官方文档](#101-官方文档)
    - [10.2 经典书籍](#102-经典书籍)
    - [10.3 在线资源](#103-在线资源)

---

## 1. 概述

### 1.1 定义与背景

可观测性（Observability）是指通过外部输出（指标、日志、追踪）来理解系统内部状态的能力。

**可观测性背景**：

- **系统复杂性**：分布式系统复杂性增加，需要更好的可观测性
- **问题定位**：快速定位和解决问题
- **性能优化**：识别性能瓶颈和优化点

### 1.2 应用价值

**可观测性价值**：

- ✅ **问题定位**：快速定位故障和性能问题
- ✅ **性能优化**：识别性能瓶颈
- ✅ **容量规划**：基于数据规划容量
- ✅ **用户体验**：提升用户体验

---

## 2. 可观测性三大支柱

### 2.1 Metrics指标

**Metrics特点**：

- **数值型数据**：数值型指标
- **时间序列**：随时间变化的序列数据
- **聚合性**：可以聚合和统计

**Metrics示例**：

```python
# Prometheus指标
redis_commands_total{command="GET",status="success"} 1000
redis_latency_seconds{command="GET",quantile="0.99"} 0.005
redis_memory_used_bytes 1073741824
```

### 2.2 Logs日志

**Logs特点**：

- **事件记录**：记录事件和操作
- **文本数据**：文本格式数据
- **详细性**：包含详细信息

**Logs示例**：

```json
{
  "timestamp": "2025-01-15T10:30:00Z",
  "level": "INFO",
  "service": "redis",
  "message": "Command executed",
  "command": "GET",
  "key": "user:123",
  "duration_ms": 0.5
}
```

### 2.3 Traces追踪

**Traces特点**：

- **请求路径**：完整的请求路径
- **关联性**：Span之间的关联关系
- **上下文**：包含上下文信息

**Traces示例**：

```text
Trace: user-request-12345
├── Span: HTTP Request (100ms)
│   ├── Span: Redis GET (5ms)
│   ├── Span: Database Query (50ms)
│   └── Span: Redis SET (3ms)
└── Span: HTTP Response (2ms)
```

---

## 3. 指标设计最佳实践

### 3.1 指标分类

**指标分类（RED方法）**：

- **Rate（速率）**：请求速率
- **Errors（错误）**：错误率
- **Duration（延迟）**：请求延迟

**指标分类（USE方法）**：

- **Utilization（利用率）**：资源利用率
- **Saturation（饱和度）**：资源饱和度
- **Errors（错误）**：错误率

**Redis指标分类**：

```python
# Rate指标
redis_commands_total{command="GET"}  # 命令总数
redis_commands_per_second{command="GET"}  # 每秒命令数

# Error指标
redis_errors_total{error_type="timeout"}  # 错误总数
redis_error_rate{error_type="timeout"}  # 错误率

# Duration指标
redis_latency_seconds{command="GET",quantile="0.99"}  # 延迟
redis_command_duration_seconds{command="GET"}  # 命令耗时

# Utilization指标
redis_memory_used_bytes  # 内存使用
redis_cpu_usage_percent  # CPU使用率

# Saturation指标
redis_connections_active  # 活跃连接数
redis_connections_max  # 最大连接数
```

### 3.2 指标命名规范

**指标命名规范**：

- **使用下划线**：使用下划线分隔单词
- **包含单位**：在指标名中包含单位
- **避免缩写**：避免使用缩写
- **一致性**：保持命名一致性

**好的指标命名**：

```python
# 好的命名
redis_command_duration_seconds
redis_memory_used_bytes
redis_connections_active_count
redis_error_rate_percent
```

**不好的指标命名**：

```python
# 不好的命名
redis_cmd_dur  # 使用缩写
redis_mem  # 不明确
redis_conn  # 不明确
```

### 3.3 指标聚合策略

**指标聚合策略**：

```python
# 按命令聚合
sum(rate(redis_commands_total[5m])) by (command)

# 按实例聚合
sum(redis_memory_used_bytes) by (instance)

# 按服务聚合
sum(redis_latency_seconds{quantile="0.99"}) by (service)
```

---

## 4. 日志设计最佳实践

### 4.1 结构化日志

**结构化日志格式**：

```json
{
  "timestamp": "2025-01-15T10:30:00Z",
  "level": "INFO",
  "service": "redis",
  "host": "redis-01",
  "message": "Command executed",
  "command": "GET",
  "key": "user:123",
  "duration_ms": 0.5,
  "client_ip": "192.168.1.100",
  "trace_id": "abc123",
  "span_id": "def456"
}
```

**结构化日志实现**：

```python
import json
import logging
from datetime import datetime

class StructuredLogger:
    def __init__(self, service_name):
        self.service_name = service_name
        self.logger = logging.getLogger(service_name)

    def log(self, level, message, **kwargs):
        """记录结构化日志"""
        log_entry = {
            'timestamp': datetime.utcnow().isoformat(),
            'level': level,
            'service': self.service_name,
            'message': message,
            **kwargs
        }

        self.logger.log(
            getattr(logging, level),
            json.dumps(log_entry)
        )

    def info(self, message, **kwargs):
        self.log('INFO', message, **kwargs)

    def error(self, message, **kwargs):
        self.log('ERROR', message, **kwargs)
```

### 4.2 日志级别使用

**日志级别使用指南**：

- **DEBUG**：详细调试信息，开发环境使用
- **INFO**：一般信息，正常操作记录
- **WARNING**：警告信息，需要关注但不影响运行
- **ERROR**：错误信息，需要立即处理
- **CRITICAL**：严重错误，系统可能无法继续运行

**日志级别使用示例**：

```python
logger.debug("Detailed debug information", extra={'key': 'value'})
logger.info("Command executed successfully", extra={'command': 'GET', 'key': 'user:123'})
logger.warning("Memory usage high", extra={'memory_percent': 85})
logger.error("Command failed", extra={'command': 'GET', 'error': 'Connection refused'})
logger.critical("System failure", extra={'error': 'Out of memory'})
```

### 4.3 日志采样策略

**日志采样策略**：

```python
import random
import logging

class SampledLogger:
    def __init__(self, base_logger, sample_rate=1.0):
        self.base_logger = base_logger
        self.sample_rate = sample_rate

    def log(self, level, message, **kwargs):
        """采样日志"""
        if random.random() < self.sample_rate:
            getattr(self.base_logger, level.lower())(message, extra=kwargs)

# 使用示例
logger = SampledLogger(logging.getLogger('redis'), sample_rate=0.1)  # 10%采样率
logger.log('INFO', 'High frequency log message')
```

---

## 5. 追踪设计最佳实践

### 5.1 Span设计

**Span设计原则**：

- **粒度适中**：不要过细也不要过粗
- **有意义**：每个Span应该代表一个有意义的操作
- **可追踪**：Span应该包含足够的上下文信息

**好的Span设计**：

```python
# 好的Span设计
with tracer.start_span('redis.get') as span:
    span.set_tag('redis.key', key)
    span.set_tag('redis.db', db)
    value = redis_client.get(key)

with tracer.start_span('redis.set') as span:
    span.set_tag('redis.key', key)
    span.set_tag('redis.value_size', len(value))
    redis_client.set(key, value)
```

**不好的Span设计**：

```python
# 不好的Span设计（过细）
with tracer.start_span('redis.connection'):
    conn = redis_client.connection_pool.get_connection()
with tracer.start_span('redis.send_command'):
    conn.send_command('GET', key)
with tracer.start_span('redis.read_response'):
    value = conn.read_response()

# 不好的Span设计（过粗）
with tracer.start_span('redis.operation'):
    # 包含多个操作
    value = redis_client.get(key)
    redis_client.set(key, value)
    redis_client.delete(key)
```

### 5.2 标签设计

**标签设计原则**：

- **有意义**：标签应该有助于问题定位
- **不敏感**：不要包含敏感信息
- **不过多**：不要添加过多标签

**好的标签设计**：

```python
span.set_tag('redis.command', 'GET')
span.set_tag('redis.key', 'user:123')
span.set_tag('redis.db', 0)
span.set_tag('redis.connection_pool_size', 10)
```

**不好的标签设计**：

```python
# 不好的标签设计（包含敏感信息）
span.set_tag('redis.password', 'secret')
span.set_tag('redis.auth_token', 'token123')

# 不好的标签设计（包含大量数据）
span.set_tag('redis.value', large_value_object)
```

### 5.3 采样策略

**采样策略**：

```python
# 固定采样率
sampler = TraceIdRatioBased(0.1)  # 10%采样率

# 自适应采样
class AdaptiveSampler:
    def __init__(self, base_rate=0.1):
        self.base_rate = base_rate
        self.error_rate = 0.0

    def should_sample(self, trace_id, parent_context=None):
        # 错误率高的服务提高采样率
        if self.error_rate > 0.1:
            return True

        # 正常采样率
        import random
        return random.random() < self.base_rate
```

---

## 6. 可观测性架构

### 6.1 数据采集层

**数据采集层架构**：

```text
应用1 ──> Agent ──┐
应用2 ──> Agent ──┼──> Collector
应用3 ──> Agent ──┘
```

**数据采集Agent**：

```python
class ObservabilityAgent:
    def __init__(self):
        self.metrics_collector = MetricsCollector()
        self.log_collector = LogCollector()
        self.trace_collector = TraceCollector()

    def collect_metrics(self):
        """采集指标"""
        return self.metrics_collector.collect()

    def collect_logs(self):
        """采集日志"""
        return self.log_collector.collect()

    def collect_traces(self):
        """采集追踪"""
        return self.trace_collector.collect()
```

### 6.2 数据存储层

**数据存储层架构**：

```text
Collector ──> Metrics Storage (Prometheus/InfluxDB)
          ──> Logs Storage (Elasticsearch/Loki)
          ──> Traces Storage (Jaeger/Zipkin)
```

**数据存储配置**：

```yaml
# 指标存储（Prometheus）
prometheus:
  retention: 30d
  storage: 100GB

# 日志存储（Elasticsearch）
elasticsearch:
  retention: 7d
  indices:
    - redis-logs-*

# 追踪存储（Jaeger）
jaeger:
  retention: 3d
  storage: elasticsearch
```

### 6.3 数据展示层

**数据展示层架构**：

```text
Storage ──> Grafana (Metrics + Logs)
        ──> Jaeger UI (Traces)
        ──> Kibana (Logs)
```

**统一Dashboard**：

```json
{
  "dashboard": {
    "panels": [
      {
        "type": "metrics",
        "dataSource": "Prometheus",
        "query": "redis_latency_seconds"
      },
      {
        "type": "logs",
        "dataSource": "Loki",
        "query": "{service=\"redis\"}"
      },
      {
        "type": "traces",
        "dataSource": "Jaeger",
        "query": "service:redis"
      }
    ]
  }
}
```

---

## 7. 成本优化

### 7.1 数据保留策略

**数据保留策略**：

```yaml
# 指标保留策略
metrics:
  raw_data: 7d      # 原始数据保留7天
  hourly_agg: 30d  # 小时聚合数据保留30天
  daily_agg: 365d  # 日聚合数据保留365天

# 日志保留策略
logs:
  hot_storage: 7d   # 热存储保留7天
  warm_storage: 30d # 温存储保留30天
  cold_storage: 90d # 冷存储保留90天

# 追踪保留策略
traces:
  hot_storage: 1d   # 热存储保留1天
  warm_storage: 7d  # 温存储保留7天
```

### 7.2 采样优化

**采样优化策略**：

```python
# 指标采样
metrics_sampler = {
    'high_frequency': 0.1,  # 高频指标10%采样
    'low_frequency': 1.0,   # 低频指标100%采样
    'error_metrics': 1.0   # 错误指标100%采样
}

# 日志采样
log_sampler = {
    'DEBUG': 0.01,   # DEBUG日志1%采样
    'INFO': 0.1,     # INFO日志10%采样
    'WARNING': 1.0,  # WARNING日志100%采样
    'ERROR': 1.0     # ERROR日志100%采样
}

# 追踪采样
trace_sampler = {
    'normal': 0.1,   # 正常请求10%采样
    'error': 1.0,    # 错误请求100%采样
    'slow': 1.0      # 慢请求100%采样
}
```

### 7.3 存储优化

**存储优化策略**：

```yaml
# 压缩配置
compression:
  metrics: gzip
  logs: gzip
  traces: gzip

# 索引优化
indexing:
  metrics:
    rollover_size: 10GB
    rollover_age: 1d
  logs:
    rollover_size: 5GB
    rollover_age: 1d
```

---

## 8. 最佳实践总结

### 8.1 指标最佳实践

- ✅ 使用RED和USE方法分类指标
- ✅ 遵循指标命名规范
- ✅ 合理设置指标聚合策略
- ✅ 定期清理无用指标

### 8.2 日志最佳实践

- ✅ 使用结构化日志格式
- ✅ 合理使用日志级别
- ✅ 实施日志采样策略
- ✅ 避免记录敏感信息

### 8.3 追踪最佳实践

- ✅ 设计合理的Span粒度
- ✅ 添加有意义的标签
- ✅ 实施采样策略
- ✅ 关联Metrics、Logs和Traces

### 8.4 成本优化最佳实践

- ✅ 设置合理的数据保留策略
- ✅ 实施采样优化
- ✅ 优化存储配置
- ✅ 定期审查和清理数据

---

## 9. 扩展阅读

- [可观测性最佳实践指南](https://opentelemetry.io/docs/)
- [Prometheus最佳实践](https://prometheus.io/docs/practices/)
- [Grafana最佳实践](https://grafana.com/docs/grafana/latest/best-practices/)

---

## 10. 权威参考

### 10.1 官方文档

- OpenTelemetry官方文档
- Prometheus官方文档
- Grafana官方文档

### 10.2 经典书籍

- 《Observability Engineering》
- 《Site Reliability Engineering》

### 10.3 在线资源

- CNCF可观测性白皮书
- 可观测性最佳实践指南
